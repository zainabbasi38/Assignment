{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "evjGLA8Jx5k8"
      },
      "outputs": [],
      "source": [
        "# Pakistan zinda bad, we love our country.\n",
        "# 0         1     2    3  4.   5.   6\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "jgK8e2vq6gvh"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "!pip install -q -U google-generativeai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "U5a_LR0V7QEY"
      },
      "outputs": [],
      "source": [
        "import google.generativeai as genai\n",
        "from google.colab import userdata\n",
        "\n",
        "\n",
        "\n",
        "genai.configure(api_key=userdata.get('GEMINI_API_KEY'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "3Q5zbNgD72OA",
        "outputId": "a45e9796-03fe-441f-e967-e9abf2c5bc48"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Model(name='models/chat-bison-001',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='PaLM 2 Chat (Legacy)',\n",
              "       description='A legacy text-only model optimized for chat conversations',\n",
              "       input_token_limit=4096,\n",
              "       output_token_limit=1024,\n",
              "       supported_generation_methods=['generateMessage', 'countMessageTokens'],\n",
              "       temperature=0.25,\n",
              "       max_temperature=None,\n",
              "       top_p=0.95,\n",
              "       top_k=40),\n",
              " Model(name='models/text-bison-001',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='PaLM 2 (Legacy)',\n",
              "       description='A legacy model that understands text and generates text as an output',\n",
              "       input_token_limit=8196,\n",
              "       output_token_limit=1024,\n",
              "       supported_generation_methods=['generateText', 'countTextTokens', 'createTunedTextModel'],\n",
              "       temperature=0.7,\n",
              "       max_temperature=None,\n",
              "       top_p=0.95,\n",
              "       top_k=40),\n",
              " Model(name='models/embedding-gecko-001',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Embedding Gecko',\n",
              "       description='Obtain a distributed representation of a text.',\n",
              "       input_token_limit=1024,\n",
              "       output_token_limit=1,\n",
              "       supported_generation_methods=['embedText', 'countTextTokens'],\n",
              "       temperature=None,\n",
              "       max_temperature=None,\n",
              "       top_p=None,\n",
              "       top_k=None),\n",
              " Model(name='models/gemini-1.0-pro-latest',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Gemini 1.0 Pro Latest',\n",
              "       description=('The original Gemini 1.0 Pro model. This model will be discontinued on '\n",
              "                    'February 15th, 2025. Move to a newer Gemini version.'),\n",
              "       input_token_limit=30720,\n",
              "       output_token_limit=2048,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=0.9,\n",
              "       max_temperature=None,\n",
              "       top_p=1.0,\n",
              "       top_k=None),\n",
              " Model(name='models/gemini-1.0-pro',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Gemini 1.0 Pro',\n",
              "       description='The best model for scaling across a wide range of tasks',\n",
              "       input_token_limit=30720,\n",
              "       output_token_limit=2048,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=0.9,\n",
              "       max_temperature=None,\n",
              "       top_p=1.0,\n",
              "       top_k=None),\n",
              " Model(name='models/gemini-pro',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Gemini 1.0 Pro',\n",
              "       description='The best model for scaling across a wide range of tasks',\n",
              "       input_token_limit=30720,\n",
              "       output_token_limit=2048,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=0.9,\n",
              "       max_temperature=None,\n",
              "       top_p=1.0,\n",
              "       top_k=None),\n",
              " Model(name='models/gemini-1.0-pro-001',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Gemini 1.0 Pro 001 (Tuning)',\n",
              "       description=('The original Gemini 1.0 Pro model version that supports tuning. Gemini 1.0 '\n",
              "                    'Pro will be discontinued on February 15th, 2025. Move to a newer Gemini '\n",
              "                    'version.'),\n",
              "       input_token_limit=30720,\n",
              "       output_token_limit=2048,\n",
              "       supported_generation_methods=['generateContent', 'countTokens', 'createTunedModel'],\n",
              "       temperature=0.9,\n",
              "       max_temperature=None,\n",
              "       top_p=1.0,\n",
              "       top_k=None),\n",
              " Model(name='models/gemini-1.0-pro-vision-latest',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Gemini 1.0 Pro Vision',\n",
              "       description=('The original Gemini 1.0 Pro Vision model version which was optimized for '\n",
              "                    'image understanding. Gemini 1.0 Pro Vision was deprecated on July 12, 2024. '\n",
              "                    'Move to a newer Gemini version.'),\n",
              "       input_token_limit=12288,\n",
              "       output_token_limit=4096,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=0.4,\n",
              "       max_temperature=None,\n",
              "       top_p=1.0,\n",
              "       top_k=32),\n",
              " Model(name='models/gemini-pro-vision',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Gemini 1.0 Pro Vision',\n",
              "       description=('The original Gemini 1.0 Pro Vision model version which was optimized for '\n",
              "                    'image understanding. Gemini 1.0 Pro Vision was deprecated on July 12, 2024. '\n",
              "                    'Move to a newer Gemini version.'),\n",
              "       input_token_limit=12288,\n",
              "       output_token_limit=4096,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=0.4,\n",
              "       max_temperature=None,\n",
              "       top_p=1.0,\n",
              "       top_k=32),\n",
              " Model(name='models/gemini-1.5-pro-latest',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Gemini 1.5 Pro Latest',\n",
              "       description=('Alias that points to the most recent production (non-experimental) release '\n",
              "                    'of Gemini 1.5 Pro, our mid-size multimodal model that supports up to 2 '\n",
              "                    'million tokens.'),\n",
              "       input_token_limit=2000000,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=40),\n",
              " Model(name='models/gemini-1.5-pro-001',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Gemini 1.5 Pro 001',\n",
              "       description=('Stable version of Gemini 1.5 Pro, our mid-size multimodal model that '\n",
              "                    'supports up to 2 million tokens, released in May of 2024.'),\n",
              "       input_token_limit=2000000,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens', 'createCachedContent'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=64),\n",
              " Model(name='models/gemini-1.5-pro-002',\n",
              "       base_model_id='',\n",
              "       version='002',\n",
              "       display_name='Gemini 1.5 Pro 002',\n",
              "       description=('Stable version of Gemini 1.5 Pro, our mid-size multimodal model that '\n",
              "                    'supports up to 2 million tokens, released in September of 2024.'),\n",
              "       input_token_limit=2000000,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens', 'createCachedContent'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=40),\n",
              " Model(name='models/gemini-1.5-pro',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Gemini 1.5 Pro',\n",
              "       description=('Stable version of Gemini 1.5 Pro, our mid-size multimodal model that '\n",
              "                    'supports up to 2 million tokens, released in May of 2024.'),\n",
              "       input_token_limit=2000000,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=40),\n",
              " Model(name='models/gemini-1.5-pro-exp-0801',\n",
              "       base_model_id='',\n",
              "       version='exp-0801',\n",
              "       display_name='Gemini Experimental 1206',\n",
              "       description='Experimental release (December 6th, 2024) of Gemini.',\n",
              "       input_token_limit=2097152,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=64),\n",
              " Model(name='models/gemini-1.5-pro-exp-0827',\n",
              "       base_model_id='',\n",
              "       version='exp-1206',\n",
              "       display_name='Gemini Experimental 1206',\n",
              "       description='Experimental release (December 6th, 2024) of Gemini.',\n",
              "       input_token_limit=2097152,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=64),\n",
              " Model(name='models/gemini-1.5-flash-latest',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Gemini 1.5 Flash Latest',\n",
              "       description=('Alias that points to the most recent production (non-experimental) release '\n",
              "                    'of Gemini 1.5 Flash, our fast and versatile multimodal model for scaling '\n",
              "                    'across diverse tasks.'),\n",
              "       input_token_limit=1000000,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=40),\n",
              " Model(name='models/gemini-1.5-flash-001',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Gemini 1.5 Flash 001',\n",
              "       description=('Stable version of Gemini 1.5 Flash, our fast and versatile multimodal model '\n",
              "                    'for scaling across diverse tasks, released in May of 2024.'),\n",
              "       input_token_limit=1000000,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens', 'createCachedContent'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=64),\n",
              " Model(name='models/gemini-1.5-flash-001-tuning',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Gemini 1.5 Flash 001 Tuning',\n",
              "       description=('Version of Gemini 1.5 Flash that supports tuning, our fast and versatile '\n",
              "                    'multimodal model for scaling across diverse tasks, released in May of 2024.'),\n",
              "       input_token_limit=16384,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens', 'createTunedModel'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=64),\n",
              " Model(name='models/gemini-1.5-flash',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Gemini 1.5 Flash',\n",
              "       description=('Alias that points to the most recent stable version of Gemini 1.5 Flash, our '\n",
              "                    'fast and versatile multimodal model for scaling across diverse tasks.'),\n",
              "       input_token_limit=1000000,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=40),\n",
              " Model(name='models/gemini-1.5-flash-exp-0827',\n",
              "       base_model_id='',\n",
              "       version='exp-1206',\n",
              "       display_name='Gemini Experimental 1206',\n",
              "       description='Experimental release (December 6th, 2024) of Gemini.',\n",
              "       input_token_limit=2097152,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=64),\n",
              " Model(name='models/gemini-1.5-flash-002',\n",
              "       base_model_id='',\n",
              "       version='002',\n",
              "       display_name='Gemini 1.5 Flash 002',\n",
              "       description=('Stable version of Gemini 1.5 Flash, our fast and versatile multimodal model '\n",
              "                    'for scaling across diverse tasks, released in September of 2024.'),\n",
              "       input_token_limit=1000000,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens', 'createCachedContent'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=40),\n",
              " Model(name='models/gemini-1.5-flash-8b',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Gemini 1.5 Flash-8B',\n",
              "       description=('Stable version of Gemini 1.5 Flash-8B, our smallest and most cost effective '\n",
              "                    'Flash model, released in October of 2024.'),\n",
              "       input_token_limit=1000000,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['createCachedContent', 'generateContent', 'countTokens'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=40),\n",
              " Model(name='models/gemini-1.5-flash-8b-001',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Gemini 1.5 Flash-8B 001',\n",
              "       description=('Stable version of Gemini 1.5 Flash-8B, our smallest and most cost effective '\n",
              "                    'Flash model, released in October of 2024.'),\n",
              "       input_token_limit=1000000,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['createCachedContent', 'generateContent', 'countTokens'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=40),\n",
              " Model(name='models/gemini-1.5-flash-8b-latest',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Gemini 1.5 Flash-8B Latest',\n",
              "       description=('Alias that points to the most recent production (non-experimental) release '\n",
              "                    'of Gemini 1.5 Flash-8B, our smallest and most cost effective Flash model, '\n",
              "                    'released in October of 2024.'),\n",
              "       input_token_limit=1000000,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['createCachedContent', 'generateContent', 'countTokens'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=40),\n",
              " Model(name='models/gemini-1.5-flash-8b-exp-0827',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Gemini 1.5 Flash 8B Experimental 0827',\n",
              "       description=('Experimental release (August 27th, 2024) of Gemini 1.5 Flash-8B, our '\n",
              "                    'smallest and most cost effective Flash model. Replaced by '\n",
              "                    'Gemini-1.5-flash-8b-001 (stable).'),\n",
              "       input_token_limit=1000000,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=40),\n",
              " Model(name='models/gemini-1.5-flash-8b-exp-0924',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Gemini 1.5 Flash 8B Experimental 0924',\n",
              "       description=('Experimental release (September 24th, 2024) of Gemini 1.5 Flash-8B, our '\n",
              "                    'smallest and most cost effective Flash model. Replaced by '\n",
              "                    'Gemini-1.5-flash-8b-001 (stable).'),\n",
              "       input_token_limit=1000000,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=40),\n",
              " Model(name='models/gemini-2.0-flash-exp',\n",
              "       base_model_id='',\n",
              "       version='2.0',\n",
              "       display_name='Gemini 2.0 Flash Experimental',\n",
              "       description='Gemini 2.0 Flash Experimental',\n",
              "       input_token_limit=1048576,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens', 'bidiGenerateContent'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=40),\n",
              " Model(name='models/gemini-exp-1206',\n",
              "       base_model_id='',\n",
              "       version='exp_1206',\n",
              "       display_name='Gemini Experimental 1206',\n",
              "       description='Experimental release (December 6th, 2024) of Gemini.',\n",
              "       input_token_limit=2097152,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=64),\n",
              " Model(name='models/gemini-exp-1121',\n",
              "       base_model_id='',\n",
              "       version='exp-1206',\n",
              "       display_name='Gemini Experimental 1206',\n",
              "       description='Experimental release (December 6th, 2024) of Gemini.',\n",
              "       input_token_limit=2097152,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=64),\n",
              " Model(name='models/gemini-exp-1114',\n",
              "       base_model_id='',\n",
              "       version='exp-1206',\n",
              "       display_name='Gemini Experimental 1206',\n",
              "       description='Experimental release (December 6th, 2024) of Gemini.',\n",
              "       input_token_limit=2097152,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=64),\n",
              " Model(name='models/gemini-2.0-flash-thinking-exp',\n",
              "       base_model_id='',\n",
              "       version='2.0',\n",
              "       display_name='Gemini 2.0 Flash Thinking Experimental',\n",
              "       description='Gemini 2.0 Flash Thinking Experimental',\n",
              "       input_token_limit=32767,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=64),\n",
              " Model(name='models/gemini-2.0-flash-thinking-exp-1219',\n",
              "       base_model_id='',\n",
              "       version='2.0',\n",
              "       display_name='Gemini 2.0 Flash Thinking Experimental',\n",
              "       description='Gemini 2.0 Flash Thinking Experimental',\n",
              "       input_token_limit=32767,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=64),\n",
              " Model(name='models/learnlm-1.5-pro-experimental',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='LearnLM 1.5 Pro Experimental',\n",
              "       description=('Alias that points to the most recent stable version of Gemini 1.5 Pro, our '\n",
              "                    'mid-size multimodal model that supports up to 2 million tokens.'),\n",
              "       input_token_limit=32767,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=64),\n",
              " Model(name='models/embedding-001',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Embedding 001',\n",
              "       description='Obtain a distributed representation of a text.',\n",
              "       input_token_limit=2048,\n",
              "       output_token_limit=1,\n",
              "       supported_generation_methods=['embedContent'],\n",
              "       temperature=None,\n",
              "       max_temperature=None,\n",
              "       top_p=None,\n",
              "       top_k=None),\n",
              " Model(name='models/text-embedding-004',\n",
              "       base_model_id='',\n",
              "       version='004',\n",
              "       display_name='Text Embedding 004',\n",
              "       description='Obtain a distributed representation of a text.',\n",
              "       input_token_limit=2048,\n",
              "       output_token_limit=1,\n",
              "       supported_generation_methods=['embedContent'],\n",
              "       temperature=None,\n",
              "       max_temperature=None,\n",
              "       top_p=None,\n",
              "       top_k=None),\n",
              " Model(name='models/aqa',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Model that performs Attributed Question Answering.',\n",
              "       description=('Model trained to return answers to questions that are grounded in provided '\n",
              "                    'sources, along with estimating answerable probability.'),\n",
              "       input_token_limit=7168,\n",
              "       output_token_limit=1024,\n",
              "       supported_generation_methods=['generateAnswer'],\n",
              "       temperature=0.2,\n",
              "       max_temperature=None,\n",
              "       top_p=1.0,\n",
              "       top_k=40)]"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "list(genai.list_models())\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "wslvg_cS6hQG",
        "outputId": "aac2699b-7a4e-44b5-f99c-193d2bab0764",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[-0.03838823,\n",
              " 0.052146558,\n",
              " -0.07062306,\n",
              " -0.037940446,\n",
              " 0.06602876,\n",
              " 0.003412638,\n",
              " 0.011060191,\n",
              " 0.011297473,\n",
              " 0.0088465065,\n",
              " 0.049196165,\n",
              " 0.026362207,\n",
              " 0.029781424,\n",
              " 0.103020616,\n",
              " 0.0018105474,\n",
              " 0.009687083,\n",
              " -0.1145385,\n",
              " 0.053375162,\n",
              " 0.027896093,\n",
              " -0.069912076,\n",
              " 0.033948876,\n",
              " 0.0021454412,\n",
              " -0.06642034,\n",
              " 0.04420987,\n",
              " -0.021766845,\n",
              " -0.05236885,\n",
              " 0.012519431,\n",
              " -0.006010968,\n",
              " -0.005167873,\n",
              " -0.0061494075,\n",
              " 0.0031098027,\n",
              " 0.025889847,\n",
              " 0.056373067,\n",
              " 0.046986956,\n",
              " -0.054916363,\n",
              " 0.02060043,\n",
              " 0.021911908,\n",
              " -0.028752202,\n",
              " 0.022969386,\n",
              " 0.0386514,\n",
              " -0.030484943,\n",
              " -0.089530766,\n",
              " 0.015129875,\n",
              " -0.06397387,\n",
              " 0.047075633,\n",
              " -0.013017894,\n",
              " -0.029871592,\n",
              " -0.0067695505,\n",
              " -0.0074492395,\n",
              " -0.0059240796,\n",
              " 0.03697813,\n",
              " 0.018429233,\n",
              " -0.001360107,\n",
              " -0.011460476,\n",
              " 0.011616342,\n",
              " -0.025911184,\n",
              " -0.05487599,\n",
              " -0.036950245,\n",
              " -0.009039906,\n",
              " 0.011936421,\n",
              " -0.002934238,\n",
              " -0.027310636,\n",
              " 6.6082706e-05,\n",
              " -0.020024965,\n",
              " -0.027493374,\n",
              " 0.002532368,\n",
              " -0.015001376,\n",
              " -0.076121554,\n",
              " 0.032683495,\n",
              " -0.092314504,\n",
              " 0.024527755,\n",
              " -0.0056760833,\n",
              " 0.012404534,\n",
              " -0.054892246,\n",
              " 0.0047428426,\n",
              " 0.027187724,\n",
              " -0.023102688,\n",
              " 0.039532688,\n",
              " -0.04834113,\n",
              " -0.032563046,\n",
              " 0.055642914,\n",
              " -0.06099361,\n",
              " 0.012322463,\n",
              " 0.05332948,\n",
              " 0.044791535,\n",
              " 0.0047311513,\n",
              " 0.03546266,\n",
              " -0.018310213,\n",
              " -0.012843131,\n",
              " -0.03281737,\n",
              " -0.015505913,\n",
              " 0.06564103,\n",
              " 0.004260769,\n",
              " 0.02080681,\n",
              " 0.015551341,\n",
              " 0.03284577,\n",
              " -0.037125297,\n",
              " -0.06909162,\n",
              " -0.12455734,\n",
              " 0.033198744,\n",
              " 0.08457165,\n",
              " -0.014386027,\n",
              " -0.03143208,\n",
              " 0.022384034,\n",
              " -0.004822828,\n",
              " 0.012416186,\n",
              " 0.031697378,\n",
              " -0.1066608,\n",
              " -0.022101557,\n",
              " -0.008450847,\n",
              " -0.0052436255,\n",
              " 0.0067770644,\n",
              " -0.058070153,\n",
              " 0.041524004,\n",
              " -0.028612824,\n",
              " 0.04088967,\n",
              " -0.028240833,\n",
              " -0.034067433,\n",
              " 0.051358417,\n",
              " -0.025877517,\n",
              " 0.028154515,\n",
              " 0.0060459366,\n",
              " 0.026830649,\n",
              " -0.00095973775,\n",
              " 0.017185919,\n",
              " 0.004395111,\n",
              " 0.016280279,\n",
              " 0.0176109,\n",
              " -0.009282771,\n",
              " 0.010105145,\n",
              " -0.03267479,\n",
              " 0.072818495,\n",
              " -0.04778589,\n",
              " 0.01858214,\n",
              " -0.0020002476,\n",
              " -0.05818697,\n",
              " -0.052377947,\n",
              " 0.0286922,\n",
              " -0.014589298,\n",
              " 0.060979374,\n",
              " 0.013860318,\n",
              " -0.0071884138,\n",
              " 0.018080251,\n",
              " -0.07651641,\n",
              " 0.0370387,\n",
              " 0.013180877,\n",
              " -0.021393348,\n",
              " -0.0080846,\n",
              " 0.025077287,\n",
              " -0.06951974,\n",
              " 0.02669913,\n",
              " -0.012492207,\n",
              " 0.01859013,\n",
              " 0.038992975,\n",
              " 0.0051947823,\n",
              " -0.047826,\n",
              " 0.018798502,\n",
              " 0.04019756,\n",
              " -0.039466992,\n",
              " 0.08624624,\n",
              " -0.00062756106,\n",
              " 0.058413763,\n",
              " -0.06800717,\n",
              " 0.029188514,\n",
              " 0.008827655,\n",
              " -0.035301555,\n",
              " -0.025547149,\n",
              " 0.025351042,\n",
              " -0.06396529,\n",
              " -0.024263415,\n",
              " -0.019369712,\n",
              " 0.013893803,\n",
              " -0.02715477,\n",
              " -0.009625998,\n",
              " -0.06395668,\n",
              " -0.058829118,\n",
              " -0.014857789,\n",
              " -0.06285088,\n",
              " -0.019081429,\n",
              " -0.025285693,\n",
              " -0.023807587,\n",
              " 0.10905102,\n",
              " 0.019630715,\n",
              " -0.018424971,\n",
              " -0.051695295,\n",
              " 0.02405902,\n",
              " -0.008708305,\n",
              " 0.013477974,\n",
              " 0.00955763,\n",
              " 0.012669435,\n",
              " 0.052519657,\n",
              " -0.04345961,\n",
              " -0.011683332,\n",
              " -0.01012757,\n",
              " 0.07052994,\n",
              " -0.0055598025,\n",
              " -0.06500708,\n",
              " -0.029050773,\n",
              " -0.020193106,\n",
              " -0.054957137,\n",
              " -0.041815933,\n",
              " 0.029825028,\n",
              " -0.0037500036,\n",
              " -0.04422032,\n",
              " -0.08507198,\n",
              " -0.025203163,\n",
              " -0.022711176,\n",
              " -0.07533748,\n",
              " 0.00038292477,\n",
              " 0.000574007,\n",
              " -0.023213899,\n",
              " -0.05437338,\n",
              " -0.020481981,\n",
              " 0.0309786,\n",
              " -0.03049663,\n",
              " 0.049754348,\n",
              " 0.01301958,\n",
              " 0.059735786,\n",
              " 0.013099316,\n",
              " 0.07402825,\n",
              " 0.0028997941,\n",
              " -0.0031488023,\n",
              " 0.030355373,\n",
              " -0.0345743,\n",
              " 0.027214795,\n",
              " 0.030471744,\n",
              " 0.00409395,\n",
              " -0.006666186,\n",
              " -0.026523612,\n",
              " 0.0037652112,\n",
              " -0.036769453,\n",
              " -0.016134802,\n",
              " 0.033313625,\n",
              " 0.0036026041,\n",
              " 0.016536806,\n",
              " 0.051247668,\n",
              " 0.090472534,\n",
              " 0.010181305,\n",
              " 0.030595109,\n",
              " 0.0070580146,\n",
              " -0.00865541,\n",
              " -0.013374387,\n",
              " 0.010765982,\n",
              " 0.048682828,\n",
              " 0.028028237,\n",
              " -0.020036707,\n",
              " -0.008994092,\n",
              " 0.012286691,\n",
              " 0.040086675,\n",
              " 0.008561659,\n",
              " -0.04989866,\n",
              " -0.03489145,\n",
              " -0.006646721,\n",
              " -0.031492487,\n",
              " -0.021983976,\n",
              " 0.0068252063,\n",
              " -0.055136193,\n",
              " 0.046041407,\n",
              " -0.014977839,\n",
              " 0.018520158,\n",
              " -0.0019085855,\n",
              " 0.036878396,\n",
              " -0.0765386,\n",
              " 0.008701385,\n",
              " -0.059513815,\n",
              " -0.060923666,\n",
              " -0.049235404,\n",
              " 0.004780061,\n",
              " 0.0044634817,\n",
              " 0.08013073,\n",
              " -0.03781426,\n",
              " -0.004155092,\n",
              " -0.07378796,\n",
              " -0.0062083392,\n",
              " 0.00019341962,\n",
              " 0.049237784,\n",
              " 0.016864326,\n",
              " 0.013317688,\n",
              " -0.020757375,\n",
              " 0.011082609,\n",
              " -0.046459932,\n",
              " -0.023551403,\n",
              " -0.0025574379,\n",
              " 0.023846528,\n",
              " -0.03697934,\n",
              " -0.018832024,\n",
              " -0.05554495,\n",
              " 0.017728858,\n",
              " -0.008121325,\n",
              " -0.021077035,\n",
              " -0.006830344,\n",
              " 0.03167001,\n",
              " 0.02122792,\n",
              " 0.053463276,\n",
              " -0.051008683,\n",
              " 0.033604734,\n",
              " 0.0053696907,\n",
              " 0.043874938,\n",
              " 0.0068859165,\n",
              " 0.035119798,\n",
              " -0.009732238,\n",
              " 0.006822771,\n",
              " 0.035985652,\n",
              " 0.010248646,\n",
              " 0.021891562,\n",
              " 0.032525573,\n",
              " 0.011882014,\n",
              " 0.05660894,\n",
              " -0.013528444,\n",
              " -0.013231257,\n",
              " -0.045601033,\n",
              " 0.048486833,\n",
              " 0.061330978,\n",
              " -0.013769018,\n",
              " -0.021071164,\n",
              " -0.05462211,\n",
              " -0.01022884,\n",
              " -0.16075553,\n",
              " 0.0055632093,\n",
              " -0.005055581,\n",
              " -0.0068281684,\n",
              " -0.03442759,\n",
              " 0.02271425,\n",
              " 0.016652118,\n",
              " 0.002752376,\n",
              " 0.043466292,\n",
              " 0.02711752,\n",
              " -0.016791742,\n",
              " -0.048889656,\n",
              " 0.03908195,\n",
              " -0.022985088,\n",
              " 0.012583863,\n",
              " 0.005726204,\n",
              " 0.023895126,\n",
              " -0.05023696,\n",
              " -0.00048284858,\n",
              " 0.008326804,\n",
              " -0.03993198,\n",
              " 0.013789181,\n",
              " 0.047209363,\n",
              " 0.027224733,\n",
              " -0.025249159,\n",
              " -0.0023370015,\n",
              " 0.043043554,\n",
              " 0.021095976,\n",
              " 0.03354987,\n",
              " -0.030191306,\n",
              " 0.02248958,\n",
              " -0.028729452,\n",
              " 0.05607367,\n",
              " -0.009501291,\n",
              " -0.023586508,\n",
              " 0.08498721,\n",
              " 0.0575211,\n",
              " -0.00075478735,\n",
              " -0.011939774,\n",
              " 0.0003264734,\n",
              " 0.060069848,\n",
              " -0.0073553207,\n",
              " 0.033479355,\n",
              " 0.0030075137,\n",
              " -0.01904192,\n",
              " -0.005860383,\n",
              " 0.023575183,\n",
              " 0.05215699,\n",
              " -5.4912136e-05,\n",
              " -0.060488857,\n",
              " -0.023957102,\n",
              " 0.012998325,\n",
              " 0.03517663,\n",
              " -0.035629902,\n",
              " 0.0369,\n",
              " 0.008402149,\n",
              " 0.001765194,\n",
              " 0.0023059861,\n",
              " 0.04675764,\n",
              " -0.04476126,\n",
              " -0.0069735753,\n",
              " -0.0002626759,\n",
              " 0.023913743,\n",
              " -0.02967791,\n",
              " 0.00031710474,\n",
              " -0.010220715,\n",
              " 0.009249499,\n",
              " 0.020453123,\n",
              " -0.03715475,\n",
              " 0.047895074,\n",
              " 0.001733521,\n",
              " 0.0037312186,\n",
              " 0.022507915,\n",
              " 0.06591765,\n",
              " -0.0115289455,\n",
              " 0.013562781,\n",
              " 0.057814762,\n",
              " 0.04246558,\n",
              " 5.7039684e-05,\n",
              " 0.033612076,\n",
              " -0.042697903,\n",
              " 0.0644634,\n",
              " -9.151293e-05,\n",
              " 0.037152737,\n",
              " -0.0011938581,\n",
              " -0.027302312,\n",
              " 0.09659006,\n",
              " 0.0012583006,\n",
              " -0.010336961,\n",
              " -0.061051127,\n",
              " 0.01347184,\n",
              " -0.0049233683,\n",
              " 0.008797497,\n",
              " 0.03161731,\n",
              " -0.03648881,\n",
              " -0.009932623,\n",
              " -0.07835084,\n",
              " 4.2173e-05,\n",
              " -0.03334824,\n",
              " 0.014768315,\n",
              " -0.015830249,\n",
              " 0.021433732,\n",
              " -0.025502263,\n",
              " 0.0038483543,\n",
              " -0.016326146,\n",
              " -0.014174781,\n",
              " -0.016782146,\n",
              " -0.020667074,\n",
              " 0.01614993,\n",
              " -0.08426387,\n",
              " -0.03154883,\n",
              " 0.01654426,\n",
              " 0.0670697,\n",
              " 0.042512123,\n",
              " 0.062353604,\n",
              " -0.030913549,\n",
              " 0.013138386,\n",
              " 0.026835408,\n",
              " 0.0110793365,\n",
              " -0.0218443,\n",
              " 0.026536738,\n",
              " -0.0064630304,\n",
              " -0.022492763,\n",
              " -0.035576217,\n",
              " -0.037078027,\n",
              " 0.01286653,\n",
              " -0.00037669428,\n",
              " 0.04966357,\n",
              " -0.0024665396,\n",
              " 0.0146915335,\n",
              " 0.06098033,\n",
              " -0.029980283,\n",
              " 0.0008697028,\n",
              " 0.064677365,\n",
              " -0.00428359,\n",
              " -0.01547883,\n",
              " -0.025234092,\n",
              " 0.025209295,\n",
              " -0.002039264,\n",
              " 0.03444799,\n",
              " -0.0022913783,\n",
              " 0.023588978,\n",
              " -0.045668975,\n",
              " 0.04170248,\n",
              " -0.044887327,\n",
              " -0.021114206,\n",
              " 0.045086056,\n",
              " 0.015677046,\n",
              " -0.0041803983,\n",
              " -0.02905689,\n",
              " -0.013574269,\n",
              " 0.070722766,\n",
              " -0.0015028456,\n",
              " -0.019128142,\n",
              " -0.026981374,\n",
              " -0.0075038965,\n",
              " 0.009927641,\n",
              " 0.011850352,\n",
              " -0.040748272,\n",
              " 0.029269002,\n",
              " 0.014578034,\n",
              " 0.04644106,\n",
              " -0.06513363,\n",
              " -0.047762387,\n",
              " 0.005994523,\n",
              " -0.016654402,\n",
              " -0.046001986,\n",
              " 0.033784177,\n",
              " -0.0059721963,\n",
              " -0.070746414,\n",
              " -0.016943036,\n",
              " -0.0011437157,\n",
              " 0.029320652,\n",
              " 0.08227695,\n",
              " 0.025052816,\n",
              " 0.0022991449,\n",
              " 0.011448173,\n",
              " -0.008304278,\n",
              " 0.019583032,\n",
              " -0.014954232,\n",
              " 0.030788248,\n",
              " 0.0029797773,\n",
              " -0.03788128,\n",
              " 0.03724129,\n",
              " 0.05528784,\n",
              " -0.034972087,\n",
              " -0.0019545844,\n",
              " -0.05261343,\n",
              " -0.056895804,\n",
              " 0.044773314,\n",
              " -0.063213706,\n",
              " -0.043816824,\n",
              " 0.0905643,\n",
              " -0.04863921,\n",
              " 0.046625808,\n",
              " 0.035758417,\n",
              " 0.011668098,\n",
              " 0.0079242475,\n",
              " -0.03298972,\n",
              " -0.011208986,\n",
              " -0.081154466,\n",
              " -0.0031484948,\n",
              " -0.017065778,\n",
              " 0.024816861,\n",
              " -0.06621424,\n",
              " -0.039437614,\n",
              " 0.042017188,\n",
              " -0.00050168845,\n",
              " 0.018247671,\n",
              " -0.024270063,\n",
              " -0.030748807,\n",
              " 0.02384947,\n",
              " 0.008581831,\n",
              " -0.032525916,\n",
              " -0.003901744,\n",
              " 0.036596827,\n",
              " 0.022501571,\n",
              " 0.014229588,\n",
              " -0.0061629214,\n",
              " 0.047474425,\n",
              " 0.01413304,\n",
              " 0.0031166582,\n",
              " 0.040364627,\n",
              " -0.019387295,\n",
              " 0.014101074,\n",
              " -0.008786798,\n",
              " -0.029672347,\n",
              " 0.02951629,\n",
              " 0.02604202,\n",
              " 0.04345717,\n",
              " -0.060620695,\n",
              " 0.025450386,\n",
              " -0.015682898,\n",
              " 0.028722597,\n",
              " -0.008685122,\n",
              " -0.010794636,\n",
              " -0.012771901,\n",
              " -0.0011217573,\n",
              " 0.005098702,\n",
              " -0.04036902,\n",
              " -0.02358411,\n",
              " -0.0033144718,\n",
              " -0.0679191,\n",
              " -0.020438666,\n",
              " -0.019104637,\n",
              " -0.03788486,\n",
              " 0.0044292295,\n",
              " 0.022491189,\n",
              " 0.0033494795,\n",
              " -0.046392314,\n",
              " 0.03587325,\n",
              " 0.04138297,\n",
              " 0.0287248,\n",
              " -0.0068671093,\n",
              " -0.0005605311,\n",
              " 0.011639575,\n",
              " 0.024345625,\n",
              " -0.060927104,\n",
              " 0.04197428,\n",
              " 0.015342221,\n",
              " -0.018747458,\n",
              " 0.008443097,\n",
              " 0.055946324,\n",
              " -0.005637669,\n",
              " 0.054343686,\n",
              " 0.018478725,\n",
              " 0.037477393,\n",
              " -0.04967184,\n",
              " 0.02941245,\n",
              " 0.010871435,\n",
              " 0.032436363,\n",
              " 0.0059494562,\n",
              " 0.04422599,\n",
              " -0.006740689,\n",
              " -0.02163518,\n",
              " 0.022332964,\n",
              " 0.017083554,\n",
              " -0.0512461,\n",
              " -0.05113343,\n",
              " -0.0320302,\n",
              " -0.048574947,\n",
              " -0.017281223,\n",
              " 0.007265277,\n",
              " -0.025888035,\n",
              " 0.0499955,\n",
              " -0.028761506,\n",
              " 0.047641512,\n",
              " 0.006997258,\n",
              " -0.055606503,\n",
              " -0.117244676,\n",
              " -0.010426683,\n",
              " -0.028365433,\n",
              " -0.018504485,\n",
              " -0.009055795,\n",
              " -0.014238359,\n",
              " -0.015719526,\n",
              " -0.03149241,\n",
              " -0.003400495,\n",
              " -0.012937613,\n",
              " -0.018243145,\n",
              " -0.0144358035,\n",
              " -0.0056894287,\n",
              " 0.054088052,\n",
              " 0.011907005,\n",
              " -0.002125421,\n",
              " -0.01782156,\n",
              " 0.0037183985,\n",
              " -0.054034688,\n",
              " -0.012775008,\n",
              " -0.020216625,\n",
              " -0.023934435,\n",
              " 0.017653301,\n",
              " 0.0046870117,\n",
              " 0.027500125,\n",
              " 0.012845098,\n",
              " 0.022624854,\n",
              " 0.03215435,\n",
              " -0.016278284,\n",
              " 0.017207153,\n",
              " 0.022287257,\n",
              " -0.004011496,\n",
              " -0.021268496,\n",
              " 0.018312145,\n",
              " -0.003118074,\n",
              " -0.0376296,\n",
              " -0.023842245,\n",
              " 0.025278052,\n",
              " 0.0063156355,\n",
              " -0.03015189,\n",
              " 0.031874474,\n",
              " -0.008299831,\n",
              " -0.0011517438,\n",
              " 0.0062523056,\n",
              " -0.00044700058,\n",
              " -0.016225612,\n",
              " -0.032361522,\n",
              " 0.020232819,\n",
              " -0.011365004,\n",
              " -0.025918007,\n",
              " 0.033456538,\n",
              " -0.0038194235,\n",
              " -0.04559527,\n",
              " 0.0091817845,\n",
              " -0.05172906,\n",
              " 0.0042541544,\n",
              " -0.020796109,\n",
              " 0.041575905,\n",
              " 0.022975706,\n",
              " -0.021847228,\n",
              " -0.007324385,\n",
              " -0.011522168,\n",
              " -0.055374276,\n",
              " 0.026773449,\n",
              " -0.020385416,\n",
              " 0.03198812,\n",
              " -0.02696582,\n",
              " 0.02701983,\n",
              " 0.032033257,\n",
              " -0.025706427,\n",
              " -0.028448839,\n",
              " 0.0704481,\n",
              " -0.023736434,\n",
              " -0.047385562,\n",
              " 0.033373505,\n",
              " -0.010090002,\n",
              " -0.027287053,\n",
              " -0.015427962,\n",
              " -0.04851017,\n",
              " 0.036831185,\n",
              " -0.012953718,\n",
              " 0.022658195,\n",
              " -0.021795256,\n",
              " 0.02059936,\n",
              " 0.024475915,\n",
              " 0.00055408303,\n",
              " -0.026111007,\n",
              " -0.03636221,\n",
              " -0.016248602,\n",
              " 0.030392338,\n",
              " 0.07902486,\n",
              " -0.024101842,\n",
              " 0.0055876803,\n",
              " -0.008215156,\n",
              " -0.023136614,\n",
              " -0.030492572,\n",
              " -0.0022403337,\n",
              " -0.035763245,\n",
              " -0.03326536,\n",
              " 0.0021086684,\n",
              " -0.010088928,\n",
              " -0.008121419,\n",
              " 0.0019507741,\n",
              " -0.073499575,\n",
              " 0.049395718,\n",
              " 0.023999428,\n",
              " -0.0007134775,\n",
              " 0.032879937,\n",
              " -0.00640119,\n",
              " 0.02869106,\n",
              " 0.013808199,\n",
              " 0.023221033,\n",
              " -0.01590115,\n",
              " 0.023822999,\n",
              " 0.08655637,\n",
              " -0.04039015,\n",
              " 0.03261114,\n",
              " 0.017652059,\n",
              " 0.03452416,\n",
              " 0.02047702,\n",
              " -0.039462328,\n",
              " -0.04694545,\n",
              " 0.038026884,\n",
              " -0.047012918,\n",
              " 0.074192934,\n",
              " 0.05681196,\n",
              " 0.0008074619,\n",
              " -0.046055894,\n",
              " 0.05716265,\n",
              " -0.019507777,\n",
              " -0.031380996,\n",
              " -0.024576735,\n",
              " -0.0037123791,\n",
              " -0.03486795,\n",
              " 0.02585528,\n",
              " 0.05651957,\n",
              " -0.054238588,\n",
              " -0.06553499,\n",
              " -0.023791313,\n",
              " -0.0122753875,\n",
              " 0.009531079,\n",
              " -0.031291775,\n",
              " -0.045523264,\n",
              " -0.015830627,\n",
              " -0.04805145,\n",
              " -0.059642047,\n",
              " 0.029825516,\n",
              " 0.05650545,\n",
              " 0.019484732,\n",
              " 0.073890746,\n",
              " 0.009196346,\n",
              " 0.030793106,\n",
              " -0.03390429,\n",
              " 0.024764318,\n",
              " 0.061629165,\n",
              " -0.043743283,\n",
              " 0.0106486445,\n",
              " 0.010411605,\n",
              " 0.0031037293,\n",
              " -0.05513253,\n",
              " -0.04937317,\n",
              " 0.004930977,\n",
              " -0.008528327]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "\n",
        "from typing import Dict\n",
        "\n",
        "result : Dict = genai.embed_content(\n",
        "    model=\"models/text-embedding-004\",\n",
        "    content=\"Pakistan zinda bad we love our country\",\n",
        "    task_type=\"retrieval_document\",\n",
        "    title=\"Embedding of single string\",\n",
        ")\n",
        "\n",
        "# # 1 input > 1 vector output\n",
        "# print(str(result[\"embedding\"])[:50], \"... TRIMMED]\")\n",
        "\n",
        "result['embedding']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4LRebzTJABUh",
        "outputId": "d2cee831-6297-4c8b-ec98-f7ffdfb106f1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "768"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "len(result['embedding'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "whzpN01Z9hPA",
        "outputId": "c0f133f6-fc8d-487d-a67d-2f15641d47fc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "768"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "len(result['embedding'])"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NHILnIETzAb9"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "id": "1ZqSNYKA84oQ",
        "outputId": "54295fc0-a383-477b-a66d-6bc48ab69efd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-0.036453027, 0.033254996, -0.03970925, -0.002628 ... TRIMMED ... 768\n",
            "[-0.01591948, 0.032582663, -0.081024624, -0.011298 ... TRIMMED ... 768\n",
            "[0.00037063024, 0.03763057, -0.122695684, -0.00951 ... TRIMMED ... 768\n"
          ]
        }
      ],
      "source": [
        "\n",
        "from typing import Dict\n",
        "\n",
        "result : Dict = genai.embed_content(\n",
        "    model=\"models/text-embedding-004\",\n",
        "    content=[\n",
        "        \"What is the meaning of life?\",\n",
        "        \"How much wood would a woodchuck chuck?\",\n",
        "        \"How does the brain work?\",\n",
        "    ],\n",
        "    task_type=\"retrieval_document\",\n",
        "    title=\"Embedding of list of strings\",\n",
        ")\n",
        "\n",
        "# A list of inputs > A list of vectors output\n",
        "for v in result[\"embedding\"]:\n",
        "    print(str(v)[:50], \"... TRIMMED ...\", len(v))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eyrCQBs8AANE"
      },
      "source": [
        "# Building Vector Stores & Retreival using Chroma DB and Langchain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GPpBBX9g-PKl",
        "outputId": "d876c7c2-060d-44a2-be60-5a3e7807f797"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/67.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m628.3/628.3 kB\u001b[0m \u001b[31m30.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m51.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.8/94.8 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m278.6/278.6 kB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m51.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.2/93.2 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.3/13.3 MB\u001b[0m \u001b[31m62.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.8/55.8 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.9/54.9 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.2/73.2 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m50.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.3/62.3 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m442.1/442.1 kB\u001b[0m \u001b[31m20.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m319.7/319.7 kB\u001b[0m \u001b[31m20.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m52.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m452.9/452.9 kB\u001b[0m \u001b[31m24.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.17.1 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3, but you have protobuf 5.29.3 which is incompatible.\n",
            "tensorflow-metadata 1.13.1 requires protobuf<5,>=3.20.3, but you have protobuf 5.29.3 which is incompatible.\n",
            "transformers 4.47.1 requires tokenizers<0.22,>=0.21, but you have tokenizers 0.20.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install -Uq langchain-chroma"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w4Wd_L8zAJTn"
      },
      "outputs": [],
      "source": [
        "import getpass\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "uxHZV_umADw5"
      },
      "outputs": [],
      "source": [
        "from langchain_core.documents import Document\n",
        "\n",
        "documents = [\n",
        "    Document(\n",
        "        page_content=\"Dogs are great companions, known for their loyalty and friendliness.\",\n",
        "        metadata={\"source\": \"mammal-pets-doc\"},\n",
        "    ),\n",
        "    Document(\n",
        "        page_content=\"Cats are independent pets that often enjoy their own space.\",\n",
        "        metadata={\"source\": \"mammal-pets-doc\"},\n",
        "    ),\n",
        "    Document(\n",
        "        page_content=\"Goldfish are popular pets for beginners, requiring relatively simple care.\",\n",
        "        metadata={\"source\": \"fish-pets-doc\"},\n",
        "    ),\n",
        "    Document(\n",
        "        page_content=\"Parrots are intelligent birds capable of mimicking human speech.\",\n",
        "        metadata={\"source\": \"bird-pets-doc\"},\n",
        "    ),\n",
        "    Document(\n",
        "        page_content=\"Rabbits are social animals that need plenty of space to hop around.\",\n",
        "        metadata={\"source\": \"mammal-pets-doc\"},\n",
        "    ),\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4kWhNtJb9z5S",
        "outputId": "002fb377-e7f2-4aae-957d-7b25f4864cee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/41.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.5/41.5 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -Uq langchain-google-genai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "4b6yLMNR9qOn"
      },
      "outputs": [],
      "source": [
        "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
        "\n",
        "embeddings = GoogleGenerativeAIEmbeddings(model=\"models/text-embedding-004\",\n",
        "                                          google_api_key=userdata.get('GEMINI_API_KEY'))\n",
        "# embeddings.embed_query(\"What's our Q1 revenue?\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "embeddings.embed_query(\"What's our Q1 revenue?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NRybEBmkp5LX",
        "outputId": "d5660f72-c7d5-4985-f796-b19068140100"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.040674030780792236,\n",
              " 0.006255019456148148,\n",
              " -0.013568978756666183,\n",
              " -0.0003686861018650234,\n",
              " 0.04303165152668953,\n",
              " 0.04935013875365257,\n",
              " -0.013514830730855465,\n",
              " -0.027903610840439796,\n",
              " -0.03995805233716965,\n",
              " -0.006844368763267994,\n",
              " 0.0013024156214669347,\n",
              " -0.009539234451949596,\n",
              " 0.0705987736582756,\n",
              " -0.009862210601568222,\n",
              " 0.03167127072811127,\n",
              " -0.02663198858499527,\n",
              " -0.018167555332183838,\n",
              " -0.005245935637503862,\n",
              " -0.14866198599338531,\n",
              " -0.01596848852932453,\n",
              " 0.02811194583773613,\n",
              " -0.0018506837077438831,\n",
              " -0.025303209200501442,\n",
              " -0.01434125192463398,\n",
              " -0.03104301728308201,\n",
              " -0.07088255137205124,\n",
              " 0.011673162691295147,\n",
              " 0.008746510371565819,\n",
              " 0.003015926806256175,\n",
              " -0.010475549846887589,\n",
              " -6.184780795592815e-05,\n",
              " -0.0014338439796119928,\n",
              " -0.03641575202345848,\n",
              " -0.0519932359457016,\n",
              " -0.02123081497848034,\n",
              " 0.03613690286874771,\n",
              " -0.03694721683859825,\n",
              " 0.06530386954545975,\n",
              " 0.031148776412010193,\n",
              " -0.05865824222564697,\n",
              " -0.033094197511672974,\n",
              " -0.002400598954409361,\n",
              " -0.039360735565423965,\n",
              " 0.001522441511042416,\n",
              " 0.03487030044198036,\n",
              " 0.0026657148264348507,\n",
              " -0.0058933584950864315,\n",
              " 0.020132659003138542,\n",
              " -0.0036536972038447857,\n",
              " 0.008130554109811783,\n",
              " -0.009108034893870354,\n",
              " -0.03555028885602951,\n",
              " -0.014387637376785278,\n",
              " 0.0020767864771187305,\n",
              " -0.047531772404909134,\n",
              " -0.023021064698696136,\n",
              " 0.02736302837729454,\n",
              " -0.026102488860487938,\n",
              " 0.08498480916023254,\n",
              " -0.009469239041209221,\n",
              " 0.0319310761988163,\n",
              " -0.0018667412223294377,\n",
              " 0.059389110654592514,\n",
              " -0.0035042506642639637,\n",
              " 0.020587773993611336,\n",
              " -0.03917128965258598,\n",
              " 0.03360649570822716,\n",
              " 0.015973566100001335,\n",
              " -0.0738484337925911,\n",
              " -0.02538050338625908,\n",
              " -0.02277788706123829,\n",
              " 0.05237537994980812,\n",
              " 0.011328230611979961,\n",
              " -0.03981751948595047,\n",
              " -0.0006608059629797935,\n",
              " -0.008069388568401337,\n",
              " 0.007512678857892752,\n",
              " -0.04804745689034462,\n",
              " 0.03459799289703369,\n",
              " 0.08978776633739471,\n",
              " -0.07167279720306396,\n",
              " 0.022603409364819527,\n",
              " 0.08019706606864929,\n",
              " 0.00940668024122715,\n",
              " 0.03418527916073799,\n",
              " -0.015340480022132397,\n",
              " -0.03552362322807312,\n",
              " -0.03181988373398781,\n",
              " -0.05383983999490738,\n",
              " -0.04403817653656006,\n",
              " 0.05618930980563164,\n",
              " -0.02780766971409321,\n",
              " -0.02107255905866623,\n",
              " -0.018637580797076225,\n",
              " 0.0897323489189148,\n",
              " -0.06604108214378357,\n",
              " -0.09660559147596359,\n",
              " -0.05220397189259529,\n",
              " 0.07147490233182907,\n",
              " 0.06639932841062546,\n",
              " 0.004779261536896229,\n",
              " -0.03112303651869297,\n",
              " 0.0008881306857801974,\n",
              " 0.01845836080610752,\n",
              " 0.0274297297000885,\n",
              " 0.0004622933629434556,\n",
              " -0.03492116928100586,\n",
              " -0.004169788211584091,\n",
              " -0.021554481238126755,\n",
              " -0.02542758919298649,\n",
              " -0.02286696434020996,\n",
              " -0.03512721508741379,\n",
              " 0.0026910000015050173,\n",
              " -0.028166597709059715,\n",
              " 0.004026286769658327,\n",
              " -0.00791264045983553,\n",
              " -0.024778082966804504,\n",
              " 0.015024474821984768,\n",
              " -0.010839731432497501,\n",
              " 0.009473622776567936,\n",
              " 0.056382134556770325,\n",
              " 0.021171119064092636,\n",
              " -0.008079694584012032,\n",
              " 0.025672005489468575,\n",
              " 0.028384380042552948,\n",
              " 0.020231332629919052,\n",
              " 0.0428866408765316,\n",
              " -0.0007346387719735503,\n",
              " -0.03555949404835701,\n",
              " -0.05524420365691185,\n",
              " -0.014625327661633492,\n",
              " 0.009426695294678211,\n",
              " 0.010897071100771427,\n",
              " -0.003945027478039265,\n",
              " 0.022394057363271713,\n",
              " -0.024528535082936287,\n",
              " 0.0876956656575203,\n",
              " 0.04642253741621971,\n",
              " -0.030577486380934715,\n",
              " 0.03828105702996254,\n",
              " 0.03191431239247322,\n",
              " -0.04186468943953514,\n",
              " -0.06275169551372528,\n",
              " 0.014168639667332172,\n",
              " -0.01498769223690033,\n",
              " -0.024832768365740776,\n",
              " 0.027766933664679527,\n",
              " -0.0004999113152734935,\n",
              " -0.025478815659880638,\n",
              " -0.03067292645573616,\n",
              " -0.027004195377230644,\n",
              " 0.005373257678002119,\n",
              " -0.005426143296062946,\n",
              " -0.013760142959654331,\n",
              " 0.047259990125894547,\n",
              " -3.351004352225573e-06,\n",
              " 0.011196448467671871,\n",
              " 0.0331735797226429,\n",
              " 0.04530906677246094,\n",
              " 0.026219498366117477,\n",
              " -0.03507794439792633,\n",
              " 0.013839093036949635,\n",
              " -0.02348119020462036,\n",
              " 0.028220539912581444,\n",
              " -0.039287421852350235,\n",
              " 0.023950839415192604,\n",
              " -0.02938219904899597,\n",
              " -0.003724222769960761,\n",
              " 0.03192543610930443,\n",
              " 0.0069425287656486034,\n",
              " -0.02548467367887497,\n",
              " -0.03700289875268936,\n",
              " -0.053304944187402725,\n",
              " -0.06592298299074173,\n",
              " -0.01140379998832941,\n",
              " 0.07297323644161224,\n",
              " -0.010483955964446068,\n",
              " -0.04604703560471535,\n",
              " -0.12386089563369751,\n",
              " -0.05467037111520767,\n",
              " 0.03335092216730118,\n",
              " 0.013243228197097778,\n",
              " -0.05039249360561371,\n",
              " -0.008832715451717377,\n",
              " 0.06478633731603622,\n",
              " 0.04017411917448044,\n",
              " 0.0036366560962051153,\n",
              " -0.026531219482421875,\n",
              " -0.015908753499388695,\n",
              " 0.006120656616985798,\n",
              " -0.01062320638448,\n",
              " 0.005162350367754698,\n",
              " 0.032537247985601425,\n",
              " -0.042312879115343094,\n",
              " 0.017654040828347206,\n",
              " 0.05063820630311966,\n",
              " 0.042538005858659744,\n",
              " -0.03213687241077423,\n",
              " -0.038917768746614456,\n",
              " 0.010565686970949173,\n",
              " -0.010164313018321991,\n",
              " -0.029124340042471886,\n",
              " 0.028939809650182724,\n",
              " -0.046825725585222244,\n",
              " -0.04041363671422005,\n",
              " -0.02851947396993637,\n",
              " -0.05352668836712837,\n",
              " -0.023540807887911797,\n",
              " -0.05905939266085625,\n",
              " 0.006182074546813965,\n",
              " 0.0236660148948431,\n",
              " 0.01643635518848896,\n",
              " -0.055969204753637314,\n",
              " -0.052113115787506104,\n",
              " 0.005142379552125931,\n",
              " 0.015834525227546692,\n",
              " 0.07765226811170578,\n",
              " 0.014419138431549072,\n",
              " 0.014757545664906502,\n",
              " -0.016682716086506844,\n",
              " 0.035169124603271484,\n",
              " -0.012445286847651005,\n",
              " 0.04094401374459267,\n",
              " -0.0004567909345496446,\n",
              " 0.03075295127928257,\n",
              " 0.015191249549388885,\n",
              " 0.0008787462138570845,\n",
              " 0.011183375492691994,\n",
              " -0.02541988343000412,\n",
              " -0.01335611566901207,\n",
              " 0.04078405350446701,\n",
              " 0.00097758905030787,\n",
              " -0.027971843257546425,\n",
              " 0.03310989588499069,\n",
              " -0.036995869129896164,\n",
              " 0.07041022926568985,\n",
              " 0.038847681134939194,\n",
              " 0.011135242879390717,\n",
              " 0.0178934745490551,\n",
              " -0.06709057837724686,\n",
              " -0.018150683492422104,\n",
              " -0.004681224934756756,\n",
              " -0.020785439759492874,\n",
              " -0.0015118676237761974,\n",
              " -0.01593458652496338,\n",
              " 0.008007141761481762,\n",
              " 0.056374192237854004,\n",
              " 0.018349969759583473,\n",
              " -0.01836358942091465,\n",
              " -0.03326503559947014,\n",
              " -0.062389075756073,\n",
              " 0.012848050333559513,\n",
              " -0.0030290777795016766,\n",
              " 0.00806711707264185,\n",
              " -0.06129119545221329,\n",
              " -0.009198661893606186,\n",
              " 0.0034411519300192595,\n",
              " -0.05829843878746033,\n",
              " 0.017203867435455322,\n",
              " 0.07828714698553085,\n",
              " 0.02788754366338253,\n",
              " -0.05472508445382118,\n",
              " -0.0053860764019191265,\n",
              " -0.04209680110216141,\n",
              " -0.057854652404785156,\n",
              " -0.06215570494532585,\n",
              " -0.037162765860557556,\n",
              " -0.026187805458903313,\n",
              " 0.013729006983339787,\n",
              " 0.00522513035684824,\n",
              " 0.007254887372255325,\n",
              " 0.007314743008464575,\n",
              " -0.044295214116573334,\n",
              " 0.012690248899161816,\n",
              " 0.0015951964305713773,\n",
              " -0.020993180572986603,\n",
              " -0.028973281383514404,\n",
              " 0.01797867938876152,\n",
              " -0.03705243021249771,\n",
              " 0.016344338655471802,\n",
              " 0.047140851616859436,\n",
              " -0.0045312875881791115,\n",
              " 0.020043889060616493,\n",
              " -0.04180380329489708,\n",
              " 0.008862539194524288,\n",
              " 0.011784982867538929,\n",
              " 0.012936141341924667,\n",
              " 0.04847110062837601,\n",
              " 0.020518505945801735,\n",
              " -0.04009382799267769,\n",
              " 0.004235445521771908,\n",
              " -0.015121255069971085,\n",
              " -0.017107676714658737,\n",
              " -0.0022628495935350657,\n",
              " 0.03131377324461937,\n",
              " 0.058326173573732376,\n",
              " 0.047612544149160385,\n",
              " 0.0008990900823846459,\n",
              " 0.012505724094808102,\n",
              " 0.0234519150108099,\n",
              " 0.011617792770266533,\n",
              " 0.0089767687022686,\n",
              " 0.012201692909002304,\n",
              " 0.05818939581513405,\n",
              " 0.07964139431715012,\n",
              " 0.02628134936094284,\n",
              " 0.0035562783014029264,\n",
              " -0.06586579233407974,\n",
              " -0.06682974845170975,\n",
              " -0.004343168810009956,\n",
              " 0.024766702204942703,\n",
              " -0.045907892286777496,\n",
              " -0.024228105321526527,\n",
              " -0.04364803433418274,\n",
              " -0.01721922867000103,\n",
              " -0.014083858579397202,\n",
              " -0.08534359931945801,\n",
              " -0.022292688488960266,\n",
              " -0.035723213106393814,\n",
              " -0.05347568914294243,\n",
              " 0.04860648512840271,\n",
              " -0.024981264024972916,\n",
              " -0.05546209588646889,\n",
              " -0.02599288523197174,\n",
              " 0.059800885617733,\n",
              " 0.027545634657144547,\n",
              " 0.010634008795022964,\n",
              " 0.030378857627511024,\n",
              " -0.06266247481107712,\n",
              " -0.02802923507988453,\n",
              " -0.0164673812687397,\n",
              " -0.00466604670509696,\n",
              " 0.0068775867111980915,\n",
              " -0.04135647043585777,\n",
              " 0.013757770881056786,\n",
              " 0.030090903863310814,\n",
              " -0.051660291850566864,\n",
              " 0.035671450197696686,\n",
              " 0.05833543464541435,\n",
              " 0.030305322259664536,\n",
              " 0.030703585594892502,\n",
              " 0.045433782041072845,\n",
              " 0.035327911376953125,\n",
              " 0.04064740985631943,\n",
              " -0.02929910458624363,\n",
              " 0.0028224694542586803,\n",
              " 0.04217402637004852,\n",
              " 0.017522307112812996,\n",
              " -0.02317088656127453,\n",
              " -0.012836667709052563,\n",
              " 0.016060883179306984,\n",
              " 0.07096286863088608,\n",
              " 0.022300882264971733,\n",
              " -0.030652055516839027,\n",
              " -0.02046220190823078,\n",
              " -0.008860406465828419,\n",
              " 0.044191617518663406,\n",
              " 0.012760547921061516,\n",
              " 0.017109554260969162,\n",
              " 0.00567222386598587,\n",
              " 0.020018693059682846,\n",
              " -0.015990694984793663,\n",
              " -0.03650399297475815,\n",
              " -0.010141105391085148,\n",
              " -0.024074191227555275,\n",
              " 0.03260262683033943,\n",
              " 0.01904658041894436,\n",
              " 0.03513059765100479,\n",
              " -0.012212435714900494,\n",
              " 0.0036663140635937452,\n",
              " -0.0070173488929867744,\n",
              " -0.03424908220767975,\n",
              " 0.036729518324136734,\n",
              " 0.01946347951889038,\n",
              " -0.00860413908958435,\n",
              " -0.04971911385655403,\n",
              " -0.059182457625865936,\n",
              " -0.002848780946806073,\n",
              " 0.031969111412763596,\n",
              " -0.026185661554336548,\n",
              " 0.05550776794552803,\n",
              " -0.004006619565188885,\n",
              " -0.051209691911935806,\n",
              " 0.06815080344676971,\n",
              " -0.05306592956185341,\n",
              " 0.020680462941527367,\n",
              " -0.07201379537582397,\n",
              " -0.01924624852836132,\n",
              " 0.005424595437943935,\n",
              " -0.043159838765859604,\n",
              " -0.004355010110884905,\n",
              " -0.0022963096853345633,\n",
              " 0.028794437646865845,\n",
              " 0.030889587476849556,\n",
              " -0.007004606071859598,\n",
              " 0.07111821323633194,\n",
              " -0.013412009924650192,\n",
              " -0.014901253394782543,\n",
              " 0.014481945894658566,\n",
              " -0.038996364921331406,\n",
              " -0.03584769740700722,\n",
              " -0.0066221775487065315,\n",
              " 0.008168015629053116,\n",
              " -0.03866076096892357,\n",
              " -0.024964667856693268,\n",
              " -0.03399388864636421,\n",
              " 0.07047809660434723,\n",
              " -0.002807113341987133,\n",
              " -0.0026940142270177603,\n",
              " -0.02858911268413067,\n",
              " 0.06441131234169006,\n",
              " 0.022924337536096573,\n",
              " -0.038946185261011124,\n",
              " -0.005655820947140455,\n",
              " -0.05000632628798485,\n",
              " -0.014447260648012161,\n",
              " -0.002026891801506281,\n",
              " 0.0030106124468147755,\n",
              " 0.05433937534689903,\n",
              " 0.0038927753921598196,\n",
              " 0.01058945618569851,\n",
              " -0.020083194598555565,\n",
              " 0.06434295326471329,\n",
              " -0.037731949239969254,\n",
              " 0.019364971667528152,\n",
              " -0.01708812639117241,\n",
              " -0.007275398354977369,\n",
              " 0.006923719309270382,\n",
              " 0.03294694796204567,\n",
              " 0.008821401745080948,\n",
              " -0.035904500633478165,\n",
              " 0.023028215393424034,\n",
              " -0.028629709035158157,\n",
              " -0.012202284298837185,\n",
              " -0.07996783405542374,\n",
              " 0.009951084852218628,\n",
              " -0.018842991441488266,\n",
              " 0.04279767721891403,\n",
              " 0.0063218362629413605,\n",
              " -0.020923594012856483,\n",
              " 0.01167957205325365,\n",
              " 0.02149077132344246,\n",
              " 0.04855334386229515,\n",
              " 0.01931636407971382,\n",
              " -0.00798702146857977,\n",
              " 0.005307495128363371,\n",
              " -0.010870776139199734,\n",
              " 0.02465776912868023,\n",
              " -0.05784374848008156,\n",
              " -0.012009432539343834,\n",
              " -0.0010353594552725554,\n",
              " 0.001357968314550817,\n",
              " 0.03233030438423157,\n",
              " -0.03482642024755478,\n",
              " -0.04115253686904907,\n",
              " -0.0016379851149395108,\n",
              " -0.016736943274736404,\n",
              " 0.03030269965529442,\n",
              " 0.0070823547430336475,\n",
              " 0.013011662289500237,\n",
              " 0.0013094530440866947,\n",
              " -0.023420250043272972,\n",
              " 0.04642616957426071,\n",
              " 0.04938816651701927,\n",
              " 0.011798360385000706,\n",
              " -0.045309584587812424,\n",
              " 0.009469387121498585,\n",
              " -0.005720063112676144,\n",
              " -0.005492646712809801,\n",
              " 0.07672107964754105,\n",
              " 0.05767561495304108,\n",
              " -0.016651729121804237,\n",
              " 0.01272104773670435,\n",
              " -0.028916891664266586,\n",
              " -0.01569833792746067,\n",
              " 0.013438977301120758,\n",
              " -0.04521883279085159,\n",
              " -0.04580063745379448,\n",
              " -0.06875801086425781,\n",
              " -0.008748088032007217,\n",
              " 0.0034978643525391817,\n",
              " -0.05619722977280617,\n",
              " -0.046840690076351166,\n",
              " 0.049902353435754776,\n",
              " 0.03386502340435982,\n",
              " -0.008411991409957409,\n",
              " -0.003451331052929163,\n",
              " -0.02074151486158371,\n",
              " 0.07574094086885452,\n",
              " -0.01795017346739769,\n",
              " 0.015205703675746918,\n",
              " 0.020769039168953896,\n",
              " -0.0004893033183179796,\n",
              " -0.04977618157863617,\n",
              " -0.06083740293979645,\n",
              " -0.011869067326188087,\n",
              " 0.04016096889972687,\n",
              " -0.0056722043082118034,\n",
              " -0.02773195691406727,\n",
              " 0.01636294275522232,\n",
              " 0.01701270416378975,\n",
              " 0.03908716142177582,\n",
              " -0.015088760294020176,\n",
              " -0.03776533156633377,\n",
              " -0.02017400600016117,\n",
              " -0.05718950182199478,\n",
              " -0.04964404180645943,\n",
              " -0.008687540888786316,\n",
              " -0.00674031674861908,\n",
              " -0.009721371345221996,\n",
              " 0.00877001229673624,\n",
              " -0.04894879087805748,\n",
              " 0.029544781893491745,\n",
              " 0.0656760111451149,\n",
              " 0.01786809228360653,\n",
              " 0.03679507598280907,\n",
              " -0.048695698380470276,\n",
              " 0.05084334313869476,\n",
              " -0.0012932618847116828,\n",
              " -0.014733269810676575,\n",
              " -0.0942688137292862,\n",
              " -0.005923083983361721,\n",
              " 0.0548890121281147,\n",
              " -0.0027005928568542004,\n",
              " 0.026992907747626305,\n",
              " -0.00731872720643878,\n",
              " -0.06826119124889374,\n",
              " -0.02900216169655323,\n",
              " 0.004012713208794594,\n",
              " 0.013650557026267052,\n",
              " 0.02704375982284546,\n",
              " 0.03710830584168434,\n",
              " 0.033099979162216187,\n",
              " 0.01301198173314333,\n",
              " -0.05733863264322281,\n",
              " 0.025459110736846924,\n",
              " 0.024094557389616966,\n",
              " -0.007090229541063309,\n",
              " -0.025551943108439445,\n",
              " 0.036184437572956085,\n",
              " 0.038272250443696976,\n",
              " -0.027310671284794807,\n",
              " 0.027453413233160973,\n",
              " 0.038615234196186066,\n",
              " 0.02579406090080738,\n",
              " 0.05250363424420357,\n",
              " 0.022117899730801582,\n",
              " -0.05710281804203987,\n",
              " -0.0017957596573978662,\n",
              " 0.03591448813676834,\n",
              " -0.005846180021762848,\n",
              " -0.06997204571962357,\n",
              " 0.00024452630896121264,\n",
              " -0.010681462474167347,\n",
              " 0.06773526221513748,\n",
              " -0.005376582033932209,\n",
              " 0.022301286458969116,\n",
              " 0.022317348048090935,\n",
              " 0.012877714820206165,\n",
              " -0.04674927517771721,\n",
              " 0.05696335807442665,\n",
              " -0.01296178437769413,\n",
              " 0.016913650557398796,\n",
              " -0.053046829998493195,\n",
              " -0.002701016841456294,\n",
              " 0.003923126962035894,\n",
              " 0.03747446462512016,\n",
              " 0.11272288858890533,\n",
              " -0.0015829706098884344,\n",
              " -0.05584847927093506,\n",
              " 0.09707442671060562,\n",
              " -0.00024738904903642833,\n",
              " -0.03714948520064354,\n",
              " -0.04195793718099594,\n",
              " 0.009514124132692814,\n",
              " 0.019299393519759178,\n",
              " -0.03335732966661453,\n",
              " 0.0021547258365899324,\n",
              " 0.053686920553445816,\n",
              " -0.03058801032602787,\n",
              " -0.0028617610223591328,\n",
              " 0.03269273787736893,\n",
              " 0.02336142770946026,\n",
              " -0.018097469583153725,\n",
              " -0.020934492349624634,\n",
              " 0.03093210980296135,\n",
              " -0.008286625146865845,\n",
              " -0.029237965121865273,\n",
              " -0.03758196532726288,\n",
              " -0.02840360254049301,\n",
              " 0.053243815898895264,\n",
              " 0.010723110288381577,\n",
              " -0.020957577973604202,\n",
              " -0.022098371759057045,\n",
              " 0.06305725127458572,\n",
              " -0.023262832313776016,\n",
              " 0.01595097780227661,\n",
              " 0.00835984107106924,\n",
              " 0.07245082408189774,\n",
              " 0.008686445653438568,\n",
              " 0.0012503870530053973,\n",
              " 7.557651406386867e-05,\n",
              " 0.03862207755446434,\n",
              " -0.019229695200920105,\n",
              " 0.014497706666588783,\n",
              " 0.012569671496748924,\n",
              " -0.026799125596880913,\n",
              " 0.019178958609700203,\n",
              " 0.026653669774532318,\n",
              " -0.014713150449097157,\n",
              " -0.00043338595423847437,\n",
              " 0.08456723392009735,\n",
              " -0.062270551919937134,\n",
              " 0.008901653811335564,\n",
              " -0.0008224630146287382,\n",
              " -0.009016134776175022,\n",
              " 0.010196023620665073,\n",
              " -0.05758286267518997,\n",
              " 0.001213831827044487,\n",
              " -0.012950764037668705,\n",
              " 0.08539506793022156,\n",
              " -0.01374772097915411,\n",
              " 0.03781634569168091,\n",
              " -0.015076442621648312,\n",
              " -0.0145783182233572,\n",
              " -0.012429311871528625,\n",
              " -0.05112070590257645,\n",
              " 0.042674072086811066,\n",
              " -0.03859506547451019,\n",
              " 0.0258342158049345,\n",
              " -0.0033613459672778845,\n",
              " -0.008885742165148258,\n",
              " 0.009936174377799034,\n",
              " 0.008650175295770168,\n",
              " -0.030997151508927345,\n",
              " 0.02414288930594921,\n",
              " 0.019081875681877136,\n",
              " 0.021299712359905243,\n",
              " -0.0016012733103707433,\n",
              " -0.03776213154196739,\n",
              " -0.007063841447234154,\n",
              " -0.010149193927645683,\n",
              " 0.018930433318018913,\n",
              " -0.030712800100445747,\n",
              " -0.0070159053429961205,\n",
              " -0.016985133290290833,\n",
              " 0.07048439234495163,\n",
              " 0.004174362868070602,\n",
              " -0.0022258968092501163,\n",
              " -0.02214689739048481,\n",
              " 0.027761224657297134,\n",
              " 0.034946225583553314,\n",
              " -0.044282216578722,\n",
              " -0.034360796213150024,\n",
              " -0.03490037843585014,\n",
              " 0.018017347902059555,\n",
              " -0.04288153350353241,\n",
              " 0.08776484429836273,\n",
              " 0.036676447838544846,\n",
              " -0.004171433392912149,\n",
              " -0.023275645449757576,\n",
              " -0.07430888712406158,\n",
              " -0.05915144830942154,\n",
              " 0.09232326596975327,\n",
              " -0.025909466668963432,\n",
              " -0.048947375267744064,\n",
              " -0.04248259216547012,\n",
              " -0.008888361044228077,\n",
              " -0.03014891780912876,\n",
              " -0.04645727202296257,\n",
              " -0.012320748530328274,\n",
              " -0.05791699141263962,\n",
              " -0.031029148027300835,\n",
              " -0.008003050461411476,\n",
              " 0.06263463944196701,\n",
              " -0.0003443692403379828,\n",
              " -0.0023389095440506935,\n",
              " -0.024600928649306297,\n",
              " -0.012160244397819042,\n",
              " 0.024075577035546303,\n",
              " 0.04455995932221413,\n",
              " -0.034846968948841095,\n",
              " 0.003009699983522296,\n",
              " -0.006747885141521692,\n",
              " 0.033100686967372894,\n",
              " 0.017554784193634987,\n",
              " 0.0066912914626300335,\n",
              " -0.03815562650561333,\n",
              " 0.03287581354379654,\n",
              " 0.008438421413302422,\n",
              " 0.05949356034398079,\n",
              " 0.05250370502471924,\n",
              " -0.025399159640073776,\n",
              " -0.00804033875465393,\n",
              " -0.0951286181807518,\n",
              " 0.04880988597869873,\n",
              " -0.030327320098876953,\n",
              " -0.00582280196249485,\n",
              " 0.06371273845434189,\n",
              " -0.008379978127777576,\n",
              " -0.01847619190812111,\n",
              " 0.0033510157372802496,\n",
              " -0.06536964327096939,\n",
              " -0.007209788542240858,\n",
              " 0.0060051498003304005,\n",
              " 0.00125016737729311,\n",
              " 0.0346645750105381,\n",
              " -0.0015321788378059864,\n",
              " -0.0008062190026976168,\n",
              " 0.012339606881141663,\n",
              " 0.004700178746134043,\n",
              " -0.014207116328179836,\n",
              " 0.048131342977285385,\n",
              " -0.028085095807909966,\n",
              " 0.0396636538207531,\n",
              " -0.026388678699731827,\n",
              " 0.02602994255721569,\n",
              " 0.005051842425018549,\n",
              " 0.061865344643592834,\n",
              " 0.07961132377386093,\n",
              " -0.03165215626358986,\n",
              " -0.019245469942688942,\n",
              " 0.047423698008060455,\n",
              " 0.029522284865379333,\n",
              " 0.0305622685700655,\n",
              " -0.04864562675356865,\n",
              " -0.05137154087424278,\n",
              " -0.03016076795756817,\n",
              " -0.010218193754553795,\n",
              " 0.02187609300017357,\n",
              " 0.06728222966194153,\n",
              " -0.058545537292957306,\n",
              " -0.07691137492656708,\n",
              " -0.04078034684062004,\n",
              " 0.02178112603724003,\n",
              " 0.004406917840242386,\n",
              " 0.01251312531530857,\n",
              " -0.01934864930808544,\n",
              " -0.00024852779461070895,\n",
              " -0.027734138071537018,\n",
              " 0.044431790709495544,\n",
              " 0.02758478745818138,\n",
              " 0.044154103845357895,\n",
              " -0.03837814927101135,\n",
              " 0.032868776470422745,\n",
              " 0.009355633519589901,\n",
              " -0.007741476874798536,\n",
              " -0.024058016017079353,\n",
              " -0.02246076613664627,\n",
              " -0.004031325690448284,\n",
              " -0.036114875227212906,\n",
              " 0.058158028870821,\n",
              " 0.0031521052587777376,\n",
              " 0.03671975061297417,\n",
              " -0.026520084589719772,\n",
              " -0.06631795316934586,\n",
              " 0.10039965808391571,\n",
              " -0.002299437765032053,\n",
              " -0.011070421896874905,\n",
              " -0.027540046721696854,\n",
              " 0.0407177172601223,\n",
              " 0.06292594969272614,\n",
              " 0.032785814255476,\n",
              " 0.021106448024511337,\n",
              " -0.04404228925704956,\n",
              " -0.005727207753807306,\n",
              " 0.06395310908555984,\n",
              " -0.007708157878369093]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "H6v2VV9lBNlb"
      },
      "outputs": [],
      "source": [
        "from langchain_chroma import Chroma\n",
        "# from langchain_openai import OpenAIEmbeddings\n",
        "\n",
        "vectorstore = Chroma.from_documents(\n",
        "    documents,\n",
        "    embedding=embeddings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D4F_AqazDjvc",
        "outputId": "39b22b27-d042-49c9-cc73-8ad31116fc6f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['_Chroma__ensure_collection',\n",
              " '_Chroma__query_collection',\n",
              " '_LANGCHAIN_DEFAULT_COLLECTION_NAME',\n",
              " '__abstractmethods__',\n",
              " '__annotations__',\n",
              " '__class__',\n",
              " '__delattr__',\n",
              " '__dict__',\n",
              " '__dir__',\n",
              " '__doc__',\n",
              " '__eq__',\n",
              " '__format__',\n",
              " '__ge__',\n",
              " '__getattribute__',\n",
              " '__gt__',\n",
              " '__hash__',\n",
              " '__init__',\n",
              " '__init_subclass__',\n",
              " '__le__',\n",
              " '__lt__',\n",
              " '__module__',\n",
              " '__ne__',\n",
              " '__new__',\n",
              " '__reduce__',\n",
              " '__reduce_ex__',\n",
              " '__repr__',\n",
              " '__setattr__',\n",
              " '__sizeof__',\n",
              " '__slots__',\n",
              " '__str__',\n",
              " '__subclasshook__',\n",
              " '__weakref__',\n",
              " '_abc_impl',\n",
              " '_asimilarity_search_with_relevance_scores',\n",
              " '_chroma_collection',\n",
              " '_client',\n",
              " '_client_settings',\n",
              " '_collection',\n",
              " '_collection_metadata',\n",
              " '_collection_name',\n",
              " '_cosine_relevance_score_fn',\n",
              " '_embedding_function',\n",
              " '_euclidean_relevance_score_fn',\n",
              " '_get_retriever_tags',\n",
              " '_max_inner_product_relevance_score_fn',\n",
              " '_persist_directory',\n",
              " '_select_relevance_score_fn',\n",
              " '_similarity_search_with_relevance_scores',\n",
              " 'aadd_documents',\n",
              " 'aadd_texts',\n",
              " 'add_documents',\n",
              " 'add_images',\n",
              " 'add_texts',\n",
              " 'adelete',\n",
              " 'afrom_documents',\n",
              " 'afrom_texts',\n",
              " 'aget_by_ids',\n",
              " 'amax_marginal_relevance_search',\n",
              " 'amax_marginal_relevance_search_by_vector',\n",
              " 'as_retriever',\n",
              " 'asearch',\n",
              " 'asimilarity_search',\n",
              " 'asimilarity_search_by_vector',\n",
              " 'asimilarity_search_with_relevance_scores',\n",
              " 'asimilarity_search_with_score',\n",
              " 'delete',\n",
              " 'delete_collection',\n",
              " 'embeddings',\n",
              " 'encode_image',\n",
              " 'from_documents',\n",
              " 'from_texts',\n",
              " 'get',\n",
              " 'get_by_ids',\n",
              " 'max_marginal_relevance_search',\n",
              " 'max_marginal_relevance_search_by_vector',\n",
              " 'override_relevance_score_fn',\n",
              " 'reset_collection',\n",
              " 'search',\n",
              " 'similarity_search',\n",
              " 'similarity_search_by_image',\n",
              " 'similarity_search_by_image_with_relevance_score',\n",
              " 'similarity_search_by_vector',\n",
              " 'similarity_search_by_vector_with_relevance_scores',\n",
              " 'similarity_search_with_relevance_scores',\n",
              " 'similarity_search_with_score',\n",
              " 'similarity_search_with_vectors',\n",
              " 'update_document',\n",
              " 'update_documents']"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "list(dir(vectorstore))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XV6SYPkLCUZf",
        "outputId": "55ed168f-867d-460b-99aa-9ec77e286617"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<langchain_chroma.vectorstores.Chroma at 0x7cfeab1f2020>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "vectorstore"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "enYsspQlCVTx",
        "outputId": "2d0c7f65-7784-4d54-fd6d-a2d645a8e3c3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(id='0f80f6bb-5d47-4b7c-b328-51c4db53d5dd', metadata={'source': 'mammal-pets-doc'}, page_content='Cats are independent pets that often enjoy their own space.'),\n",
              " Document(id='b9fb3f6e-af15-44c6-9c06-d846fa632934', metadata={'source': 'mammal-pets-doc'}, page_content='Dogs are great companions, known for their loyalty and friendliness.'),\n",
              " Document(id='d032a828-3864-4837-b820-af260c24e280', metadata={'source': 'fish-pets-doc'}, page_content='Goldfish are popular pets for beginners, requiring relatively simple care.'),\n",
              " Document(id='9a82abb8-8710-49cc-a865-f723046545c5', metadata={'source': 'mammal-pets-doc'}, page_content='Rabbits are social animals that need plenty of space to hop around.')]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "vectorstore.similarity_search(\"cat\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WhUxC04ODcB_",
        "outputId": "539661fb-fcae-489e-d0d2-3003ea5498d2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(id='0f80f6bb-5d47-4b7c-b328-51c4db53d5dd', metadata={'source': 'mammal-pets-doc'}, page_content='Cats are independent pets that often enjoy their own space.'),\n",
              " Document(id='b9fb3f6e-af15-44c6-9c06-d846fa632934', metadata={'source': 'mammal-pets-doc'}, page_content='Dogs are great companions, known for their loyalty and friendliness.'),\n",
              " Document(id='d032a828-3864-4837-b820-af260c24e280', metadata={'source': 'fish-pets-doc'}, page_content='Goldfish are popular pets for beginners, requiring relatively simple care.'),\n",
              " Document(id='9a82abb8-8710-49cc-a865-f723046545c5', metadata={'source': 'mammal-pets-doc'}, page_content='Rabbits are social animals that need plenty of space to hop around.')]"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "await vectorstore.asimilarity_search(\"cat\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WqdDbqlqD66I",
        "outputId": "9b807856-1066-40e1-b474-ac5041b26cea"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(Document(id='0f80f6bb-5d47-4b7c-b328-51c4db53d5dd', metadata={'source': 'mammal-pets-doc'}, page_content='Cats are independent pets that often enjoy their own space.'),\n",
              "  0.6688324213027954),\n",
              " (Document(id='b9fb3f6e-af15-44c6-9c06-d846fa632934', metadata={'source': 'mammal-pets-doc'}, page_content='Dogs are great companions, known for their loyalty and friendliness.'),\n",
              "  0.9940857887268066),\n",
              " (Document(id='d032a828-3864-4837-b820-af260c24e280', metadata={'source': 'fish-pets-doc'}, page_content='Goldfish are popular pets for beginners, requiring relatively simple care.'),\n",
              "  1.103921890258789),\n",
              " (Document(id='9a82abb8-8710-49cc-a865-f723046545c5', metadata={'source': 'mammal-pets-doc'}, page_content='Rabbits are social animals that need plenty of space to hop around.'),\n",
              "  1.1072404384613037)]"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "# Note that providers implement different scores; Chroma here\n",
        "# returns a distance metric that should vary inversely with\n",
        "# similarity.\n",
        "\n",
        "vectorstore.similarity_search_with_score(\"cat\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "M5wF724BDNb5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e17052e8-6b2c-4b63-ace6-da67781035f6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(id='0f80f6bb-5d47-4b7c-b328-51c4db53d5dd', metadata={'source': 'mammal-pets-doc'}, page_content='Cats are independent pets that often enjoy their own space.'),\n",
              " Document(id='b9fb3f6e-af15-44c6-9c06-d846fa632934', metadata={'source': 'mammal-pets-doc'}, page_content='Dogs are great companions, known for their loyalty and friendliness.'),\n",
              " Document(id='d032a828-3864-4837-b820-af260c24e280', metadata={'source': 'fish-pets-doc'}, page_content='Goldfish are popular pets for beginners, requiring relatively simple care.'),\n",
              " Document(id='9a82abb8-8710-49cc-a865-f723046545c5', metadata={'source': 'mammal-pets-doc'}, page_content='Rabbits are social animals that need plenty of space to hop around.')]"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "embedding = embeddings.embed_query(\"cat\")# convert cat into vector\n",
        "\n",
        "vectorstore.similarity_search_by_vector(embedding)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "fVH5rbdBFGiR"
      },
      "outputs": [],
      "source": [
        "# embedding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZJBBUPFvFkym"
      },
      "source": [
        "# Retrievers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ndnSdfyoEsfz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d843f21-bb31-4f60-ac95-20ebcff99fbe"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[Document(metadata={'source': 'fish-pets-doc'}, page_content='Goldfish are popular pets for beginners, requiring relatively simple care.')]]"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ],
      "source": [
        "from langchain_core.documents import Document\n",
        "from langchain_core.runnables import RunnableLambda\n",
        "\n",
        "retriever = RunnableLambda(vectorstore.similarity_search).bind(k=1)  # select top result\n",
        "\n",
        "retriever.batch([\"shark\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B5Qg_8mtGExp"
      },
      "outputs": [],
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "\n",
        "\n",
        "llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\",\n",
        "                             api_key = userdata.get('GOOGLE_API_KEY')\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# llm.invoke(\"tell about cats?\")"
      ],
      "metadata": {
        "id": "1fgbKdBavfzx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vEIe1ORnGv5P"
      },
      "outputs": [],
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "\n",
        "message = \"\"\"\n",
        "Answer this question using the provided context only.\n",
        "\n",
        "{question}\n",
        "\n",
        "Context:\n",
        "{context}\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EXqbnfyduxwa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rKGDcuBQI63Z"
      },
      "outputs": [],
      "source": [
        "prompt = ChatPromptTemplate.from_messages([(\"human\", message)])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# RAG"
      ],
      "metadata": {
        "id": "auiitSfgu4GG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sc2yWh5BJJuR"
      },
      "outputs": [],
      "source": [
        "rag_chain = {\"context\": retriever, \"question\": RunnablePassthrough()} | prompt | llm\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bs3oaRLCJHDp"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PiJt_KJSJHBf"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hFCGSNa3Jn5j",
        "outputId": "44db87e6-fff5-481d-e67f-28ac8d64a8cc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The provided text does not contain any information about sharks.\n"
          ]
        }
      ],
      "source": [
        "response = rag_chain.invoke(\"tell about shark?\")\n",
        "\n",
        "print(response.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kv5FmiyvL0x_"
      },
      "source": [
        "# Now use google gemini embedding model for retriver\n",
        "https://python.langchain.com/api_reference/google_genai/embeddings/langchain_google_genai.embeddings.GoogleGenerativeAIEmbeddings.html#langchain_google_genai.embeddings.GoogleGenerativeAIEmbeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Os-OJ_8ySpgr"
      },
      "source": [
        "# Face detection with embedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QeQQ9ohuUMqS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e2a30a40-4b2a-4cef-9b85-4bf38d422d48"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.9 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━\u001b[0m \u001b[32m1.5/1.9 MB\u001b[0m \u001b[31m47.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m29.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m52.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m755.5/755.5 MB\u001b[0m \u001b[31m846.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m81.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m68.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m39.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m167.9/167.9 MB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m90.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchaudio 2.5.1+cu121 requires torch==2.5.1, but you have torch 2.2.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install -Uq facenet-pytorch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EeWUwMq_ONLJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d4a34825-e2af-4025-c704-e752c3df14a9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/4.5 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.5/4.5 MB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m67.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m47.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "facenet-pytorch 2.6.0 requires Pillow<10.3.0,>=10.2.0, but you have pillow 11.1.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install -Uq pillow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VLF-hrWBKmod"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.models as models\n",
        "\n",
        "import torchvision.transforms as transforms\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "22HAeuDqTolW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "2ce2cdbfdd4d44939090b222e561440b",
            "e3a87c1b2fe24f41a169c76c46dd7e8d",
            "ae9bf4536dc8413083a3e30058195f57",
            "0bfa5dc73eca43dea3cd9bc2bd65da99",
            "051bef3984264e45a46c6b7d77bc9bf6",
            "9cf4ba41050c4429bf9971792b44436a",
            "dd2c74038ad5442495ddbab7696cee52",
            "926afd6328d546c69d7807a1a38c4fa4",
            "281c1287cca54141bb01681de8b391d1",
            "09de6b2d0d8849708685ce674426c1c4",
            "9847c2aefcaa43ceb2db27639043574e"
          ]
        },
        "outputId": "72ef64b3-fec4-4bd3-fa42-766e18eb5f2a"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0.00/107M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2ce2cdbfdd4d44939090b222e561440b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "InceptionResnetV1(\n",
              "  (conv2d_1a): BasicConv2d(\n",
              "    (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
              "    (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (relu): ReLU()\n",
              "  )\n",
              "  (conv2d_2a): BasicConv2d(\n",
              "    (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
              "    (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (relu): ReLU()\n",
              "  )\n",
              "  (conv2d_2b): BasicConv2d(\n",
              "    (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "    (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (relu): ReLU()\n",
              "  )\n",
              "  (maxpool_3a): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (conv2d_3b): BasicConv2d(\n",
              "    (conv): Conv2d(64, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "    (bn): BatchNorm2d(80, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (relu): ReLU()\n",
              "  )\n",
              "  (conv2d_4a): BasicConv2d(\n",
              "    (conv): Conv2d(80, 192, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
              "    (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (relu): ReLU()\n",
              "  )\n",
              "  (conv2d_4b): BasicConv2d(\n",
              "    (conv): Conv2d(192, 256, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
              "    (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (relu): ReLU()\n",
              "  )\n",
              "  (repeat_1): Sequential(\n",
              "    (0): Block35(\n",
              "      (branch0): BasicConv2d(\n",
              "        (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (branch1): Sequential(\n",
              "        (0): BasicConv2d(\n",
              "          (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (1): BasicConv2d(\n",
              "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "      )\n",
              "      (branch2): Sequential(\n",
              "        (0): BasicConv2d(\n",
              "          (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (1): BasicConv2d(\n",
              "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (2): BasicConv2d(\n",
              "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "      )\n",
              "      (conv2d): Conv2d(96, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (1): Block35(\n",
              "      (branch0): BasicConv2d(\n",
              "        (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (branch1): Sequential(\n",
              "        (0): BasicConv2d(\n",
              "          (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (1): BasicConv2d(\n",
              "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "      )\n",
              "      (branch2): Sequential(\n",
              "        (0): BasicConv2d(\n",
              "          (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (1): BasicConv2d(\n",
              "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (2): BasicConv2d(\n",
              "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "      )\n",
              "      (conv2d): Conv2d(96, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (2): Block35(\n",
              "      (branch0): BasicConv2d(\n",
              "        (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (branch1): Sequential(\n",
              "        (0): BasicConv2d(\n",
              "          (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (1): BasicConv2d(\n",
              "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "      )\n",
              "      (branch2): Sequential(\n",
              "        (0): BasicConv2d(\n",
              "          (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (1): BasicConv2d(\n",
              "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (2): BasicConv2d(\n",
              "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "      )\n",
              "      (conv2d): Conv2d(96, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (3): Block35(\n",
              "      (branch0): BasicConv2d(\n",
              "        (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (branch1): Sequential(\n",
              "        (0): BasicConv2d(\n",
              "          (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (1): BasicConv2d(\n",
              "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "      )\n",
              "      (branch2): Sequential(\n",
              "        (0): BasicConv2d(\n",
              "          (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (1): BasicConv2d(\n",
              "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (2): BasicConv2d(\n",
              "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "      )\n",
              "      (conv2d): Conv2d(96, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (4): Block35(\n",
              "      (branch0): BasicConv2d(\n",
              "        (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (branch1): Sequential(\n",
              "        (0): BasicConv2d(\n",
              "          (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (1): BasicConv2d(\n",
              "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "      )\n",
              "      (branch2): Sequential(\n",
              "        (0): BasicConv2d(\n",
              "          (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (1): BasicConv2d(\n",
              "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (2): BasicConv2d(\n",
              "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "      )\n",
              "      (conv2d): Conv2d(96, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "  )\n",
              "  (mixed_6a): Mixed_6a(\n",
              "    (branch0): BasicConv2d(\n",
              "      (conv): Conv2d(256, 384, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
              "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (branch1): Sequential(\n",
              "      (0): BasicConv2d(\n",
              "        (conv): Conv2d(256, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (1): BasicConv2d(\n",
              "        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (2): BasicConv2d(\n",
              "        (conv): Conv2d(192, 256, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
              "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "    )\n",
              "    (branch2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (repeat_2): Sequential(\n",
              "    (0): Block17(\n",
              "      (branch0): BasicConv2d(\n",
              "        (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (branch1): Sequential(\n",
              "        (0): BasicConv2d(\n",
              "          (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (1): BasicConv2d(\n",
              "          (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (2): BasicConv2d(\n",
              "          (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "      )\n",
              "      (conv2d): Conv2d(256, 896, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (1): Block17(\n",
              "      (branch0): BasicConv2d(\n",
              "        (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (branch1): Sequential(\n",
              "        (0): BasicConv2d(\n",
              "          (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (1): BasicConv2d(\n",
              "          (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (2): BasicConv2d(\n",
              "          (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "      )\n",
              "      (conv2d): Conv2d(256, 896, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (2): Block17(\n",
              "      (branch0): BasicConv2d(\n",
              "        (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (branch1): Sequential(\n",
              "        (0): BasicConv2d(\n",
              "          (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (1): BasicConv2d(\n",
              "          (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (2): BasicConv2d(\n",
              "          (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "      )\n",
              "      (conv2d): Conv2d(256, 896, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (3): Block17(\n",
              "      (branch0): BasicConv2d(\n",
              "        (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (branch1): Sequential(\n",
              "        (0): BasicConv2d(\n",
              "          (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (1): BasicConv2d(\n",
              "          (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (2): BasicConv2d(\n",
              "          (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "      )\n",
              "      (conv2d): Conv2d(256, 896, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (4): Block17(\n",
              "      (branch0): BasicConv2d(\n",
              "        (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (branch1): Sequential(\n",
              "        (0): BasicConv2d(\n",
              "          (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (1): BasicConv2d(\n",
              "          (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (2): BasicConv2d(\n",
              "          (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "      )\n",
              "      (conv2d): Conv2d(256, 896, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (5): Block17(\n",
              "      (branch0): BasicConv2d(\n",
              "        (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (branch1): Sequential(\n",
              "        (0): BasicConv2d(\n",
              "          (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (1): BasicConv2d(\n",
              "          (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (2): BasicConv2d(\n",
              "          (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "      )\n",
              "      (conv2d): Conv2d(256, 896, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (6): Block17(\n",
              "      (branch0): BasicConv2d(\n",
              "        (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (branch1): Sequential(\n",
              "        (0): BasicConv2d(\n",
              "          (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (1): BasicConv2d(\n",
              "          (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (2): BasicConv2d(\n",
              "          (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "      )\n",
              "      (conv2d): Conv2d(256, 896, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (7): Block17(\n",
              "      (branch0): BasicConv2d(\n",
              "        (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (branch1): Sequential(\n",
              "        (0): BasicConv2d(\n",
              "          (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (1): BasicConv2d(\n",
              "          (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (2): BasicConv2d(\n",
              "          (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "      )\n",
              "      (conv2d): Conv2d(256, 896, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (8): Block17(\n",
              "      (branch0): BasicConv2d(\n",
              "        (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (branch1): Sequential(\n",
              "        (0): BasicConv2d(\n",
              "          (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (1): BasicConv2d(\n",
              "          (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (2): BasicConv2d(\n",
              "          (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "      )\n",
              "      (conv2d): Conv2d(256, 896, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (9): Block17(\n",
              "      (branch0): BasicConv2d(\n",
              "        (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (branch1): Sequential(\n",
              "        (0): BasicConv2d(\n",
              "          (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (1): BasicConv2d(\n",
              "          (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (2): BasicConv2d(\n",
              "          (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "      )\n",
              "      (conv2d): Conv2d(256, 896, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "  )\n",
              "  (mixed_7a): Mixed_7a(\n",
              "    (branch0): Sequential(\n",
              "      (0): BasicConv2d(\n",
              "        (conv): Conv2d(896, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (1): BasicConv2d(\n",
              "        (conv): Conv2d(256, 384, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
              "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "    )\n",
              "    (branch1): Sequential(\n",
              "      (0): BasicConv2d(\n",
              "        (conv): Conv2d(896, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (1): BasicConv2d(\n",
              "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
              "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "    )\n",
              "    (branch2): Sequential(\n",
              "      (0): BasicConv2d(\n",
              "        (conv): Conv2d(896, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (1): BasicConv2d(\n",
              "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (2): BasicConv2d(\n",
              "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
              "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "    )\n",
              "    (branch3): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (repeat_3): Sequential(\n",
              "    (0): Block8(\n",
              "      (branch0): BasicConv2d(\n",
              "        (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (branch1): Sequential(\n",
              "        (0): BasicConv2d(\n",
              "          (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (1): BasicConv2d(\n",
              "          (conv): Conv2d(192, 192, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
              "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (2): BasicConv2d(\n",
              "          (conv): Conv2d(192, 192, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
              "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "      )\n",
              "      (conv2d): Conv2d(384, 1792, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (1): Block8(\n",
              "      (branch0): BasicConv2d(\n",
              "        (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (branch1): Sequential(\n",
              "        (0): BasicConv2d(\n",
              "          (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (1): BasicConv2d(\n",
              "          (conv): Conv2d(192, 192, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
              "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (2): BasicConv2d(\n",
              "          (conv): Conv2d(192, 192, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
              "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "      )\n",
              "      (conv2d): Conv2d(384, 1792, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (2): Block8(\n",
              "      (branch0): BasicConv2d(\n",
              "        (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (branch1): Sequential(\n",
              "        (0): BasicConv2d(\n",
              "          (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (1): BasicConv2d(\n",
              "          (conv): Conv2d(192, 192, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
              "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (2): BasicConv2d(\n",
              "          (conv): Conv2d(192, 192, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
              "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "      )\n",
              "      (conv2d): Conv2d(384, 1792, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (3): Block8(\n",
              "      (branch0): BasicConv2d(\n",
              "        (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (branch1): Sequential(\n",
              "        (0): BasicConv2d(\n",
              "          (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (1): BasicConv2d(\n",
              "          (conv): Conv2d(192, 192, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
              "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (2): BasicConv2d(\n",
              "          (conv): Conv2d(192, 192, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
              "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "      )\n",
              "      (conv2d): Conv2d(384, 1792, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (4): Block8(\n",
              "      (branch0): BasicConv2d(\n",
              "        (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (branch1): Sequential(\n",
              "        (0): BasicConv2d(\n",
              "          (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (1): BasicConv2d(\n",
              "          (conv): Conv2d(192, 192, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
              "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (2): BasicConv2d(\n",
              "          (conv): Conv2d(192, 192, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
              "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "      )\n",
              "      (conv2d): Conv2d(384, 1792, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "  )\n",
              "  (block8): Block8(\n",
              "    (branch0): BasicConv2d(\n",
              "      (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (branch1): Sequential(\n",
              "      (0): BasicConv2d(\n",
              "        (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (1): BasicConv2d(\n",
              "        (conv): Conv2d(192, 192, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
              "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "      (2): BasicConv2d(\n",
              "        (conv): Conv2d(192, 192, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
              "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "      )\n",
              "    )\n",
              "    (conv2d): Conv2d(384, 1792, kernel_size=(1, 1), stride=(1, 1))\n",
              "  )\n",
              "  (avgpool_1a): AdaptiveAvgPool2d(output_size=1)\n",
              "  (dropout): Dropout(p=0.6, inplace=False)\n",
              "  (last_linear): Linear(in_features=1792, out_features=512, bias=False)\n",
              "  (last_bn): BatchNorm1d(512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (logits): Linear(in_features=512, out_features=8631, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ],
      "source": [
        "from facenet_pytorch import MTCNN, InceptionResnetV1\n",
        "\n",
        "model = InceptionResnetV1(pretrained='vggface2').eval()\n",
        "model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YtY6raX6Vrsp"
      },
      "outputs": [],
      "source": [
        "# Preprocessing function to transform the image into a tensor\n",
        "def preprocess_image(image_path):\n",
        "    image = Image.open(image_path).convert('RGB')\n",
        "    preprocess = transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "    ])\n",
        "    return preprocess(image).unsqueeze(0)\n",
        "\n",
        "# Function to create image embeddings\n",
        "def create_image_embedding(image_path):\n",
        "    try:\n",
        "        input_tensor = preprocess_image(image_path)\n",
        "        with torch.no_grad():\n",
        "            embeddings = model(input_tensor)# ebedding important line\n",
        "        return embeddings.squeeze().numpy()\n",
        "    except Exception as e:\n",
        "        print(\"Error:\", e)\n",
        "        return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_0AcRHbRVslq"
      },
      "outputs": [],
      "source": [
        "!mkdir images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dhtkU-0lV1-O"
      },
      "outputs": [],
      "source": [
        "# prompt: create python function where we provide image url and imag_name then it save in images folder\n",
        "\n",
        "import requests\n",
        "import os\n",
        "\n",
        "def save_image_from_url(image_url, image_name):\n",
        "  \"\"\"\n",
        "  Downloads an image from a URL and saves it to the 'images' folder.\n",
        "\n",
        "  Args:\n",
        "    image_url: The URL of the image to download.\n",
        "    image_name: The name of the file to save the image as.\n",
        "  \"\"\"\n",
        "  try:\n",
        "    if not os.path.exists(\"images\"):\n",
        "      os.makedirs(\"images\")\n",
        "\n",
        "    image_path = os.path.join(\"images\", image_name)\n",
        "\n",
        "    response = requests.get(image_url, stream=True)\n",
        "    response.raise_for_status()  # Raise an exception for bad status codes\n",
        "\n",
        "    with open(image_path, 'wb') as file:\n",
        "      for chunk in response.iter_content(chunk_size=8192):\n",
        "        file.write(chunk)\n",
        "\n",
        "    print(f\"Image saved to: {image_path}\")\n",
        "  except requests.exceptions.RequestException as e:\n",
        "    print(f\"Error downloading image: {e}\")\n",
        "  except Exception as e:\n",
        "    print(f\"An error occurred: {e}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "01gSmY8gX8ep",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f8000ad4-43c7-4601-ea00-70185e739ae6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image saved to: images/s1.jpg\n",
            "Image saved to: images/q1.jpg\n",
            "Image saved to: images/z1.jpg\n",
            "Image saved to: images/z2.jpg\n",
            "Image saved to: images/s2.jpg\n",
            "Image saved to: images/q2.jpg\n"
          ]
        }
      ],
      "source": [
        "save_image_from_url(\"https://media.licdn.com/dms/image/v2/D4E03AQEEn9DuNlQwvw/profile-displayphoto-shrink_200_200/profile-displayphoto-shrink_200_200/0/1664654245747?e=2147483647&v=beta&t=NGB0a9aqsgdyxpbuO3rqws95ogJnL_6aRtBDS7IWPfw\",\"s1.jpg\")\n",
        "save_image_from_url(\"https://avatars.githubusercontent.com/u/10209765?v=4\", \"q1.jpg\")\n",
        "\n",
        "save_image_from_url(\"https://media.licdn.com/dms/image/v2/D4D22AQFmuEiR8ttUmw/feedshare-shrink_800/feedshare-shrink_800/0/1711203894556?e=2147483647&v=beta&t=GEZGp_cdogNJCJIGidoEw_DjW2FXZcG4nUUlaNF1Zlc\",\"z1.jpg\")\n",
        "save_image_from_url(\"https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcQBBiqefc7Le97Rn0udVVBkur7RlU53FcQh1A&s\",'z2.jpg')\n",
        "save_image_from_url(\"https://scontent.fkhi4-4.fna.fbcdn.net/v/t39.30808-6/468785380_10160566910882765_300507882801991935_n.jpg?_nc_cat=103&ccb=1-7&_nc_sid=6ee11a&_nc_eui2=AeEk77SJKagGymTo3ibNnnx9YsjCm8DJ0lRiyMKbwMnSVMJqs7YWsJDuzKzXyLHLoFk&_nc_ohc=QJMm9K-AE4QQ7kNvgFE0N2o&_nc_oc=Adi1r8eogMcuDIMMLJvliCOnaaXQ2KnUbbJvY94aAnfInkDB-fyB_1ZXBpDQnWTkZnY&_nc_zt=23&_nc_ht=scontent.fkhi4-4.fna&_nc_gid=AcSynbwc6ukNTxWnUzjhtEe&oh=00_AYCvnF-vj63T-X69PZgBk6JvVjepzybVukgHPSM_6BXkGQ&oe=678003A4\",'s2.jpg')\n",
        "save_image_from_url(\"https://i.ytimg.com/vi/7QD3GKvSyMk/hqdefault.jpg?sqp=-oaymwEmCOADEOgC8quKqQMa8AEB-AHOBYAC0AWKAgwIABABGGUgXChPMA8=&rs=AOn4CLB2EaZsLrClGHqUMUhApQ_sxAcF7Q\",\"q2.jpg\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CZJON-xwV-bl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a509449-6cc5-407a-b9a6-9d204c61bed9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error downloading image: No connection adapters were found for 'data:image/jpeg;base64,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'\n"
          ]
        }
      ],
      "source": [
        "save_image_from_url(\"data:image/jpeg;base64,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\",\"q2.jpg\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZtpE6lWvW3gD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a100f029-e21c-4915-8623-6d1718c379ca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image Embedding Shape: (512,)\n",
            "Image Embedding: [ 0.00058278 -0.01463297 -0.10330155  0.03984535  0.08525636  0.08029363\n",
            " -0.01011138  0.04867227 -0.00259888 -0.0077198  -0.0331905   0.06225294\n",
            "  0.01708761 -0.00982595 -0.01638006  0.00054205  0.04426373  0.00519726\n",
            "  0.04448376 -0.08979201 -0.06033407 -0.00162232  0.09186839  0.03262272\n",
            "  0.06873461  0.02532319  0.03512866 -0.05809444  0.00151727  0.05172818\n",
            " -0.04107905 -0.03755797 -0.04134395 -0.00761167 -0.00674731  0.04443471\n",
            "  0.00570058 -0.02845279 -0.12002273  0.05528227  0.00132485  0.00437373\n",
            " -0.02495593  0.01842853 -0.00357915  0.01889837  0.02980521  0.10357354\n",
            " -0.11238679 -0.02633037  0.02794239 -0.0152881   0.04015452 -0.0039458\n",
            " -0.09202526  0.0715652  -0.03382103  0.07384298  0.01921727 -0.04263638\n",
            "  0.02758526  0.03841295 -0.04435986 -0.05347932 -0.04511738  0.03700717\n",
            " -0.00194125 -0.00450149  0.03157888  0.02796174  0.02416223  0.01202647\n",
            " -0.00905218  0.00880154  0.0189873  -0.01363976 -0.0499587  -0.01557556\n",
            "  0.02297474  0.0651246   0.0614766   0.02845725  0.00367925  0.03151315\n",
            " -0.00906348  0.04034334  0.00219301  0.05856943 -0.00909011 -0.01423355\n",
            "  0.01797742  0.01435157  0.05880354 -0.04344825  0.10147727 -0.04386036\n",
            " -0.01284018  0.02154127 -0.06004561  0.05457702  0.04566431 -0.01077684\n",
            "  0.00699712  0.02765366  0.00357566  0.05447806 -0.01310005 -0.02255299\n",
            "  0.01432354 -0.07601233  0.04908508  0.00389152 -0.06607237 -0.08058616\n",
            "  0.0263547  -0.02808471  0.0695286  -0.00038021 -0.03878854  0.02984364\n",
            " -0.00256646  0.02118442  0.00133815 -0.0472773  -0.01195588 -0.0669666\n",
            " -0.0071366   0.04453232  0.00111025 -0.02842125 -0.0175714  -0.00643478\n",
            "  0.04876323 -0.06472842 -0.09787413  0.00334867  0.00187649 -0.00024767\n",
            "  0.06938788  0.10385709 -0.02833053 -0.00792771 -0.00623726  0.03481311\n",
            "  0.07992636 -0.05045125 -0.00808156  0.00769071  0.05459293 -0.06051681\n",
            "  0.02623133 -0.04237332 -0.01461612  0.07601271  0.02316507 -0.06920444\n",
            "  0.05341151  0.0485434   0.03503026 -0.02546098  0.07508431  0.04377884\n",
            " -0.02852262  0.02682048  0.09139965  0.04641375 -0.05197915 -0.02836282\n",
            " -0.06560951  0.04164857 -0.01279163 -0.00395267 -0.00660236  0.00338493\n",
            "  0.05723305  0.04263638  0.04826457 -0.02185955 -0.08236013  0.0287613\n",
            " -0.04757535 -0.00422647 -0.08301193  0.06606403  0.04168128  0.04225906\n",
            "  0.03009798  0.05508625  0.02304784  0.02956334  0.02328967 -0.03885793\n",
            "  0.09149846 -0.09700762  0.05365682 -0.02802743  0.06186439  0.04086529\n",
            " -0.02531239  0.06880185  0.03396954 -0.05555064  0.02037002 -0.04165684\n",
            "  0.03669901  0.0640901   0.03570412 -0.00553594  0.04140023  0.02657003\n",
            " -0.06931031 -0.03869386 -0.04545971  0.01155922 -0.00488004  0.0426462\n",
            " -0.0636877   0.03799228 -0.02469095 -0.01786827 -0.11714919 -0.0975224\n",
            " -0.01709365 -0.05293322 -0.00160847  0.03877039 -0.06770448 -0.00353634\n",
            " -0.01539879 -0.00023611 -0.009705    0.0525001  -0.01574586 -0.05584005\n",
            "  0.02420623 -0.00578888  0.01579252 -0.07729022 -0.02444515 -0.02403441\n",
            " -0.01252517 -0.0195509   0.01120158 -0.01532311  0.09776177  0.07899044\n",
            " -0.01579785  0.03239097 -0.01639406  0.05716111  0.05955906  0.07648396\n",
            "  0.01000867 -0.00473776  0.04412794 -0.02058393  0.02995613  0.03681798\n",
            "  0.0209659   0.05551313 -0.00472502 -0.01202328  0.02113431 -0.01948468\n",
            " -0.05865138 -0.02253946  0.06847092  0.00293734 -0.03504635  0.01365006\n",
            " -0.09010956 -0.00802817 -0.04642696 -0.02624361 -0.06792872 -0.05286164\n",
            "  0.02717434  0.01057739  0.01564983 -0.06623219  0.06408169  0.03001962\n",
            " -0.01631466 -0.04925485 -0.02576832 -0.04653771 -0.01977751 -0.00355507\n",
            " -0.03372259 -0.07618748  0.02066366 -0.06482755  0.03217461 -0.01092269\n",
            " -0.01718775 -0.02406414  0.00717621  0.07962366  0.03695744  0.03045471\n",
            "  0.09488815  0.00117036  0.02282127  0.01545661  0.03193149 -0.03805847\n",
            " -0.03073642 -0.06083288 -0.02635645  0.0254594  -0.02669582  0.01615116\n",
            "  0.01507757  0.01439681  0.04895734  0.02372173 -0.04542394  0.06016143\n",
            "  0.00688547 -0.00513737  0.10314457  0.01167683 -0.04161828  0.01970115\n",
            " -0.07644531  0.07899482  0.02732771  0.02116577  0.05548168  0.03341798\n",
            "  0.04803425  0.02059413 -0.00346371  0.06049509  0.00493905 -0.04375328\n",
            "  0.01996547  0.03197958  0.04180827  0.02040025  0.05875337  0.01775215\n",
            "  0.03359037 -0.00116151 -0.03342745 -0.02892528 -0.01895843  0.05830195\n",
            "  0.03731528 -0.04010315  0.01020672  0.02329778 -0.04411007 -0.08327088\n",
            " -0.05110124  0.01217918  0.09359314 -0.02469934 -0.02297806 -0.03897167\n",
            "  0.02345902  0.00067792 -0.06096138 -0.01937438 -0.02764596  0.01525408\n",
            "  0.07700519 -0.03905027  0.00822655 -0.03271889 -0.07537898 -0.01849484\n",
            "  0.01702019  0.0040585   0.0699041   0.04940457 -0.06243282 -0.00178328\n",
            " -0.01065948 -0.00928921 -0.02235799 -0.05218275 -0.06756899  0.0613427\n",
            "  0.00699825 -0.03643901 -0.02644681 -0.01890211  0.02612516 -0.03388806\n",
            "  0.00105624  0.05355155 -0.00194111 -0.02571725 -0.04154576 -0.00361628\n",
            "  0.08862311  0.03117609  0.06117413  0.02730942 -0.08572201  0.08137289\n",
            "  0.00439804 -0.00416813 -0.01750178  0.01217526  0.00269837 -0.04631697\n",
            "  0.05641455 -0.00846761  0.04905433 -0.02528094  0.00193327 -0.02050643\n",
            " -0.02846969 -0.00645685  0.05126152  0.03582475  0.0033618  -0.04733974\n",
            "  0.02973489 -0.0122521  -0.03350455  0.06956115 -0.0429418   0.00483133\n",
            "  0.02245149 -0.00588596  0.02491498 -0.06521189  0.01002998  0.04180297\n",
            " -0.0244523   0.00798181 -0.05623091 -0.04452998  0.01560469  0.00986408\n",
            " -0.02810116 -0.01782225 -0.05889104 -0.0351436  -0.00859083  0.10779268\n",
            " -0.01023237  0.06080008 -0.10309302  0.01397533  0.02526072 -0.07942653\n",
            "  0.01960654  0.05659704  0.00549258 -0.09367355  0.0263099  -0.00264487\n",
            " -0.00870358  0.09565648  0.07037158  0.00666058  0.01199247  0.04150009\n",
            " -0.03298025  0.02638438  0.06660346 -0.05924815 -0.09617335  0.01599596\n",
            "  0.03302556 -0.00165851  0.00336149 -0.00456443  0.00200567 -0.02196456\n",
            " -0.09801189 -0.00093401  0.09824389 -0.00995049  0.00316581  0.03275843\n",
            " -0.00061821  0.01058625  0.00352063 -0.02993771  0.03894569  0.05737574\n",
            " -0.10843383  0.02968427  0.05140879 -0.06388002  0.01988242 -0.04600152\n",
            " -0.03955155  0.00290028  0.07266345 -0.01782443 -0.0110463  -0.0075507\n",
            "  0.03013197  0.01059503 -0.03528689 -0.004358    0.02702685 -0.01792463\n",
            "  0.00025843  0.06066977  0.06143346  0.03103392 -0.02381746 -0.01173486\n",
            "  0.04217441 -0.06347054]\n"
          ]
        }
      ],
      "source": [
        "# Example usage\n",
        "image_path = \"./images/q2.jpg\"\n",
        "q2 = create_image_embedding(image_path)\n",
        "\n",
        "# 'embedding' now contains a dense vector representation of the image\n",
        "print(\"Image Embedding Shape:\", q2.shape)\n",
        "print(\"Image Embedding:\", q2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XmPsgV__Z5D-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa26c4ce-ee21-4c8c-de7a-eb32d0648d4a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image Embedding Shape: (512,)\n",
            "Image Embedding: [-1.11871092e-02 -1.03831679e-01 -6.49788529e-02  6.26160726e-02\n",
            "  5.31825311e-02  2.93166805e-02  2.85817944e-02  1.07557606e-02\n",
            "  2.30576918e-02  2.11645626e-02  4.49966975e-02 -1.05079694e-03\n",
            "  5.12558147e-02 -1.57793239e-02  2.27004047e-02  4.33514714e-02\n",
            " -4.31503728e-02  3.46557088e-02  3.98752280e-02  4.01685536e-02\n",
            "  1.22629656e-02  3.47619690e-02  3.74376588e-02 -2.92636734e-02\n",
            " -1.95951890e-02  7.84217790e-02 -1.65973324e-02 -7.39309639e-02\n",
            "  1.87867340e-02 -3.93897295e-02 -3.14862356e-02  2.39189509e-02\n",
            " -2.03516819e-02 -3.26003097e-02  3.72588672e-02  1.85265020e-02\n",
            "  4.76108380e-02 -1.18853813e-02 -3.72915268e-02 -1.12608625e-02\n",
            " -1.34668415e-02  2.98970081e-02 -4.51772660e-02 -4.26033661e-02\n",
            " -5.81922904e-02 -1.54332519e-02  4.68713380e-02  8.94587934e-02\n",
            " -5.68718724e-02  1.97885297e-02 -1.02427714e-02  3.88370454e-02\n",
            "  1.36065371e-02  3.18910480e-02 -3.45597640e-02  1.28371874e-02\n",
            "  4.65074666e-02  5.49756736e-02 -4.13392968e-02 -1.22491121e-02\n",
            "  8.02586153e-02  3.81988622e-02 -5.95349297e-02 -4.23814692e-02\n",
            " -3.49300839e-02 -1.36340754e-02  1.65573079e-02 -9.17057693e-02\n",
            "  4.65478487e-02  4.74346522e-03 -7.06184953e-02  3.83565389e-02\n",
            " -2.63459440e-02 -2.60344408e-02  3.11261583e-02  1.57261752e-02\n",
            " -2.50283480e-02 -3.79884839e-02 -4.75553572e-02 -9.30941955e-04\n",
            "  2.56992294e-03 -1.16410665e-02 -2.28207912e-02 -1.37971453e-02\n",
            "  1.74771342e-03  3.25816385e-02  7.12756664e-02  8.06502923e-02\n",
            " -8.84141400e-02  3.10803317e-02  1.12167420e-02 -5.51299080e-02\n",
            "  2.68588867e-02  5.49648777e-02  5.49707972e-02  3.85880768e-02\n",
            "  6.21338785e-02 -4.84648123e-02 -8.64821225e-02  3.40486951e-02\n",
            " -1.84795298e-02 -1.02242075e-01  5.26406690e-02  1.47886546e-02\n",
            " -1.00119589e-02 -9.87762213e-02 -3.48315723e-02 -1.60418544e-02\n",
            "  5.70422830e-03  1.07697593e-02  4.71926183e-02  2.86004227e-02\n",
            " -7.81947225e-02 -1.11674763e-01 -2.46943682e-02 -6.18855916e-02\n",
            "  4.04402800e-02 -5.76940831e-03 -3.66969779e-02  8.73905346e-02\n",
            " -1.95407961e-03 -7.69524351e-02  2.24794121e-03  4.49692048e-02\n",
            " -3.32978033e-02 -2.64183376e-02 -7.62605900e-03 -4.31122668e-02\n",
            " -4.82989699e-02 -4.19171266e-02  6.26357496e-02 -1.28543442e-02\n",
            "  3.03642172e-02 -6.85790405e-02 -7.44268671e-02  4.44427580e-02\n",
            "  4.89318557e-02  7.48089999e-02  5.43042049e-02  6.00816235e-02\n",
            " -7.12566264e-03  8.05306341e-03  3.31095867e-02  7.52047971e-02\n",
            "  6.79623038e-02 -1.45985046e-02  1.66600458e-02  1.66200865e-02\n",
            " -1.90182421e-02 -2.40901653e-02  3.60215753e-02 -4.52494761e-03\n",
            " -2.01554149e-02 -3.92694548e-02 -6.22260990e-03 -6.53752685e-02\n",
            "  2.25214642e-02  1.63132250e-01  2.94811204e-02  1.35595500e-02\n",
            "  1.56537015e-02 -4.26869951e-02 -5.20180166e-02  2.30753869e-02\n",
            "  2.58502923e-02  4.04522233e-02 -7.47844577e-02 -9.00941938e-02\n",
            "  5.50987013e-02  1.23147229e-02  6.08907044e-02 -7.16004241e-03\n",
            "  5.38712330e-02 -8.02025273e-02  5.18828854e-02 -4.00018580e-02\n",
            " -5.88896498e-02 -1.56445596e-02 -6.38517365e-02  7.16072917e-02\n",
            " -9.03155804e-02  2.27934793e-02 -6.62763342e-02  6.39582053e-04\n",
            "  2.69628260e-02  5.58275171e-02  7.03577921e-02 -6.42892485e-03\n",
            " -7.07693622e-02 -5.25698066e-02 -2.28427649e-02 -1.37585355e-02\n",
            "  5.22842593e-02 -3.93862315e-02 -1.84570011e-02 -1.30426968e-02\n",
            " -1.33173876e-02  1.35453995e-02 -2.80390326e-02  5.79056144e-02\n",
            "  7.42083117e-02  4.26574275e-02 -7.73473307e-02 -7.72884861e-02\n",
            " -6.86476380e-02  4.26337533e-02 -3.17118168e-02 -3.85838673e-02\n",
            " -3.27074490e-02  2.25020368e-02 -5.35984933e-02 -8.51002261e-02\n",
            " -2.57829379e-04 -5.79836592e-02 -4.83230464e-02  6.95719942e-02\n",
            " -5.70446579e-03  3.79940495e-02  3.91066223e-02  8.65514018e-03\n",
            " -1.94135103e-02 -8.58654976e-02 -2.17920132e-02 -3.61560769e-02\n",
            "  1.96798276e-02  7.68107409e-03 -4.60527949e-02 -6.16294369e-02\n",
            "  1.40599320e-02 -1.96032431e-02  3.69630717e-02  3.76747772e-02\n",
            " -3.93913011e-04 -5.43305613e-02 -4.82097920e-03  7.32045919e-02\n",
            "  2.96099130e-02 -1.40450243e-02 -7.42208771e-03 -1.03640500e-02\n",
            " -3.25925536e-02 -3.01711783e-02 -1.41784605e-02  1.91026032e-02\n",
            "  1.19687105e-02  5.49073629e-02 -1.27675049e-02  1.89592652e-02\n",
            " -3.60129704e-03  4.07527685e-02  1.58893522e-02 -3.44600640e-02\n",
            "  1.06150880e-02  3.84745449e-02  6.57472461e-02  3.69573571e-02\n",
            " -7.59413615e-02  7.12694554e-03  1.02292381e-01  3.07430904e-02\n",
            " -1.42631624e-02 -3.66568081e-02  4.19115573e-02  2.91144066e-02\n",
            " -2.39088945e-02 -1.75305735e-02  2.30969545e-02  1.10883974e-02\n",
            " -2.20475420e-02  9.80181340e-03  5.87587245e-03  3.13788243e-02\n",
            " -6.55176118e-02  2.09741853e-03  5.72765693e-02 -1.58681860e-03\n",
            " -4.68703508e-02 -1.52097307e-02 -7.16491938e-02  2.99625471e-02\n",
            " -6.92216959e-03 -3.35283726e-02 -2.81945970e-02 -3.25089544e-02\n",
            " -6.62789941e-02 -4.97282185e-02 -3.42484340e-02 -2.92028184e-03\n",
            " -3.12268082e-02 -2.36473512e-03  6.91680908e-02 -5.72880507e-02\n",
            "  2.19719894e-02  7.09659457e-02 -9.11697820e-02  8.05146247e-03\n",
            " -3.67003754e-02 -3.51633504e-02 -3.51897813e-02 -4.24067210e-03\n",
            "  7.31516723e-03  3.96723077e-02  1.22136600e-01  9.59074348e-02\n",
            "  3.37592028e-02 -8.30706581e-02 -4.62482125e-02  5.29494435e-02\n",
            " -6.37108311e-02 -7.88331628e-02  2.41478123e-02  3.51880379e-02\n",
            "  3.10061988e-03 -8.55734048e-04  9.33466479e-03  9.05917734e-02\n",
            " -5.29304240e-03 -5.91451349e-03 -3.49753648e-02 -3.79948057e-02\n",
            " -1.01735713e-02  1.44569213e-02 -3.40275578e-02  5.79419993e-02\n",
            " -6.94063231e-02  5.42249419e-02  4.10679402e-03 -2.00269953e-03\n",
            " -3.38053657e-03  5.25264814e-02  8.21771193e-03 -1.42585263e-02\n",
            "  3.32685071e-03  4.92198113e-03 -6.54617976e-03  1.02857854e-02\n",
            "  8.78617838e-02 -5.40974829e-03 -4.90192790e-03 -2.69505940e-02\n",
            "  1.16487309e-01 -1.11756781e-02 -5.35591925e-03  1.03215575e-02\n",
            "  9.29426774e-03 -6.83753490e-02 -5.87190082e-03  5.61574586e-02\n",
            " -2.96462979e-02 -1.24421641e-02 -2.96109170e-02  3.14039290e-02\n",
            "  1.07058501e-02  1.78728383e-02  1.22983707e-02  3.82478572e-02\n",
            "  8.27867389e-02 -2.93790568e-02  8.19675811e-03  3.53541337e-02\n",
            "  1.54894055e-03  6.46627173e-02  1.66487310e-03 -4.24213782e-02\n",
            " -7.26400912e-02  6.79494515e-02  8.68740026e-03 -8.92815646e-03\n",
            "  2.97773303e-03 -3.14534493e-02 -2.34413091e-02  2.59234216e-02\n",
            " -3.53894010e-02  1.58237852e-02 -9.52033792e-03 -1.04601365e-02\n",
            " -3.72940972e-02  9.96353384e-03  3.83030740e-03  1.09600406e-02\n",
            " -2.67700199e-03  3.83338295e-02  6.69002682e-02  5.93743697e-02\n",
            "  1.16633736e-01 -6.55779615e-02 -1.49554471e-02 -3.90407965e-02\n",
            " -3.73179391e-02  3.14061157e-02  5.28097264e-02 -3.25627774e-02\n",
            " -3.03207189e-02 -4.85909283e-02 -3.29659134e-02 -2.05135643e-02\n",
            "  2.61528362e-02  3.25204283e-02  3.23005988e-05 -2.75909379e-02\n",
            " -6.97963536e-02 -3.12910601e-03 -1.11005129e-02  1.16420761e-02\n",
            " -8.27886760e-02  5.85027412e-02 -1.77270323e-02 -2.46270373e-02\n",
            " -1.12117054e-02 -4.60258499e-02  5.06376028e-02 -3.59613001e-02\n",
            "  9.49118193e-03 -3.65367532e-02 -6.32456467e-02 -7.98258279e-03\n",
            "  1.70360636e-02  1.34473937e-02  9.58526693e-03 -5.80657721e-02\n",
            "  4.14541624e-02 -3.09430752e-02 -1.94751471e-02  4.93912958e-02\n",
            "  6.71683857e-03  5.04589938e-02  4.60711122e-02  8.14810675e-03\n",
            "  4.14786424e-04 -5.30870110e-02  4.03976515e-02  3.44096720e-02\n",
            "  2.18358040e-02  8.94732028e-03 -8.08790401e-02  1.38119273e-02\n",
            "  4.42448147e-02  2.45676450e-02 -8.20356831e-02 -2.84231603e-02\n",
            " -2.38482263e-02  4.76225354e-02 -6.49007410e-02  4.62613478e-02\n",
            "  1.12036755e-02 -6.22173846e-02 -2.37915777e-02  1.36410967e-02\n",
            " -5.50070927e-02 -4.87210602e-03  4.57302146e-02  3.77252176e-02\n",
            "  4.11336459e-02 -6.46088272e-03  7.15470240e-02 -1.30598292e-01\n",
            "  5.94469868e-02  5.49982078e-02  6.16098642e-02  4.15492579e-02\n",
            " -1.65865161e-02  9.11596268e-02  1.50168948e-02  5.86488023e-02\n",
            "  3.52287665e-02  5.36219515e-02 -2.27170866e-02  2.38616634e-02\n",
            "  5.69305196e-02 -5.61067089e-02 -1.63862202e-02 -7.68495025e-03\n",
            " -7.35249231e-03 -2.82694027e-02 -2.63305176e-02 -1.63035244e-02\n",
            " -2.63792966e-02 -2.06475402e-03 -3.17978999e-03 -1.68414932e-04\n",
            " -3.67765166e-02  8.34158901e-03  9.04802233e-02 -5.55233611e-03\n",
            "  5.70693016e-02  4.57675941e-02  6.21742709e-03  8.65672948e-04\n",
            " -4.08265274e-03 -8.40259567e-02  1.97605304e-02 -2.01635025e-02\n",
            "  5.56236785e-03  6.52863011e-02  1.03389621e-01  2.02528182e-02\n",
            "  1.90992840e-02 -2.93199196e-02 -1.71488412e-02 -4.66644801e-02\n",
            " -6.03761850e-03 -1.08810216e-02 -1.04834288e-02 -1.31510189e-02\n",
            " -3.51735875e-02 -1.67632438e-02  4.90136743e-02 -1.90571100e-02\n",
            "  2.45440360e-02  1.26176523e-02 -3.38700116e-02 -2.57172789e-02]\n"
          ]
        }
      ],
      "source": [
        "image_path = \"./images/s2.jpg\"\n",
        "cat2 = create_image_embedding(image_path)\n",
        "\n",
        "# 'embedding' now contains a dense vector representation of the image\n",
        "print(\"Image Embedding Shape:\", cat2.shape)\n",
        "print(\"Image Embedding:\", cat2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qGsGyHm7Z7GG"
      },
      "outputs": [],
      "source": [
        "q1 = create_image_embedding(\"./images/q1.jpg\")\n",
        "q2 = create_image_embedding(\"./images/q2.jpg\")\n",
        "s1 = create_image_embedding(\"./images/s1.jpg\")\n",
        "s2 = create_image_embedding(\"./images/s2.jpg\")\n",
        "z1 = create_image_embedding(\"./images/z1.jpg\")\n",
        "z2 = create_image_embedding(\"./images/z2.jpg\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EaGMoOeMatEn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 793
        },
        "outputId": "0baeb637-e9b0-41a7-db90-cad11d621477"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting milvus-lite\n",
            "  Downloading milvus_lite-2.4.11-py3-none-manylinux2014_x86_64.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from milvus-lite) (4.67.1)\n",
            "Downloading milvus_lite-2.4.11-py3-none-manylinux2014_x86_64.whl (45.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.2/45.2 MB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: milvus-lite\n",
            "Successfully installed milvus-lite-2.4.11\n",
            "Collecting pymilvus\n",
            "  Downloading pymilvus-2.5.3-py3-none-any.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: setuptools>69 in /usr/local/lib/python3.10/dist-packages (from pymilvus) (75.1.0)\n",
            "Collecting grpcio<=1.67.1,>=1.49.1 (from pymilvus)\n",
            "  Downloading grpcio-1.67.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.9 kB)\n",
            "Requirement already satisfied: protobuf>=3.20.0 in /usr/local/lib/python3.10/dist-packages (from pymilvus) (5.29.2)\n",
            "Requirement already satisfied: python-dotenv<2.0.0,>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from pymilvus) (1.0.1)\n",
            "Collecting ujson>=2.0.0 (from pymilvus)\n",
            "  Downloading ujson-5.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.3 kB)\n",
            "Requirement already satisfied: pandas>=1.2.4 in /usr/local/lib/python3.10/dist-packages (from pymilvus) (2.2.2)\n",
            "Requirement already satisfied: milvus-lite>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from pymilvus) (2.4.11)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from milvus-lite>=2.4.0->pymilvus) (4.67.1)\n",
            "Requirement already satisfied: numpy>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2.4->pymilvus) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2.4->pymilvus) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2.4->pymilvus) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2.4->pymilvus) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas>=1.2.4->pymilvus) (1.17.0)\n",
            "Downloading pymilvus-2.5.3-py3-none-any.whl (229 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m229.9/229.9 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading grpcio-1.67.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.9/5.9 MB\u001b[0m \u001b[31m72.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ujson-5.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (53 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.6/53.6 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: ujson, grpcio, pymilvus\n",
            "  Attempting uninstall: grpcio\n",
            "    Found existing installation: grpcio 1.68.1\n",
            "    Uninstalling grpcio-1.68.1:\n",
            "      Successfully uninstalled grpcio-1.68.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.17.1 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3, but you have protobuf 5.29.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed grpcio-1.67.1 pymilvus-2.5.3 ujson-5.10.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "grpc"
                ]
              },
              "id": "098605876ee04ad8ad3f72d04bef70ba"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install -U milvus-lite\n",
        "\n",
        "!pip install -U pymilvus\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8VCan5cjbCBW"
      },
      "outputs": [],
      "source": [
        "from pymilvus import MilvusClient\n",
        "client = MilvusClient(\"./milvus_demo.db\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lhSATnNMaZmf"
      },
      "outputs": [],
      "source": [
        "from pymilvus import MilvusClient\n",
        "import numpy as np\n",
        "\n",
        "client = MilvusClient(\"./milvus_demo.db\")\n",
        "client.create_collection(\n",
        "    collection_name=\"images\",\n",
        "    dimension=512  # The vectors we will use in this demo has 384 dimensions\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bB-wjZmIarV3"
      },
      "outputs": [],
      "source": [
        "data = [\n",
        "    {\"id\": 1, \"person_name\": \"Qasim\", \"vector\": q1},\n",
        "    {\"id\": 2, \"person_name\": \"Qasim\", \"vector\": q2},\n",
        "    {\"id\": 3, \"person_name\": \"Shahzad\", \"vector\": s1},\n",
        "    {\"id\": 4, \"person_name\": \"Shahzad\", \"vector\": s2},\n",
        "    {\"id\": 5, \"person_name\": \"Zia Khan\", \"vector\": z1},\n",
        "    {\"id\": 6, \"person_name\": \"Zia Khan\", \"vector\": z2}\n",
        "]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pPFMGNspcEnF"
      },
      "outputs": [],
      "source": [
        "res = client.insert(\n",
        "    collection_name=\"images\",\n",
        "    data=data\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0E3TbHNIaZsF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "423905c6-b663-4b3d-f19a-b4f6f2306f43"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data: [\"[{'id': 3, 'distance': 1.0, 'entity': {'person_name': 'Shahzad', 'id': 3}}]\"] \n"
          ]
        }
      ],
      "source": [
        "res = client.search(\n",
        "    collection_name=\"images\",\n",
        "    data=[s1],\n",
        "    limit=1,\n",
        "    output_fields=[\"id\", \"person_name\"],\n",
        ")\n",
        "print(res)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CWjC3uQyaZ0h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c11a9eab-5e53-4ad0-8c67-001a2677c3f3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 7.49765784e-02, -3.95101458e-02, -3.39875631e-02,  3.52344252e-02,\n",
              "        8.82505812e-03, -9.46294330e-03, -2.02523619e-02,  3.26745561e-04,\n",
              "       -1.25470031e-02, -1.70428045e-02,  1.14811892e-02, -4.24311645e-02,\n",
              "       -5.85023779e-03,  1.51661877e-02,  6.88413382e-02,  2.30133291e-02,\n",
              "       -7.88090006e-03,  5.66428602e-02, -7.11421948e-03,  2.42894143e-03,\n",
              "        1.88995767e-02,  4.74441871e-02,  5.68169169e-02,  1.30824992e-05,\n",
              "       -2.91658957e-02,  5.05764037e-02,  8.83970316e-03, -5.82928099e-02,\n",
              "       -1.60568617e-02, -7.94354975e-02,  2.07029209e-02,  9.93780717e-02,\n",
              "        1.28378011e-02,  5.21188825e-02,  4.21005161e-03, -1.89065561e-02,\n",
              "        3.68318595e-02,  3.10832984e-03, -4.76457998e-02, -5.60111664e-02,\n",
              "       -1.16198752e-02, -5.90130202e-02,  1.02151297e-02, -1.85261946e-03,\n",
              "        1.15303956e-02, -2.90563554e-02, -9.58734378e-03, -1.97601859e-02,\n",
              "       -9.42032412e-02,  1.53519837e-02,  2.53812093e-02,  2.14174315e-02,\n",
              "        2.21368554e-03,  1.46285398e-02, -4.69658971e-02, -2.02091355e-02,\n",
              "        4.22882941e-03, -3.25385015e-03,  7.23441988e-02,  2.23042276e-02,\n",
              "        7.19925901e-03,  1.65719166e-02, -3.79756764e-02, -1.16910478e-02,\n",
              "       -1.67125147e-02,  3.46974134e-02, -5.93688758e-03, -5.00005186e-02,\n",
              "        5.81429452e-02,  2.45740842e-02, -5.24211712e-02, -6.71044737e-02,\n",
              "        6.30113930e-02,  4.78395522e-02,  3.35798301e-02,  1.48839457e-02,\n",
              "       -1.88941583e-02, -4.63252664e-02, -4.83563058e-02,  1.32286269e-02,\n",
              "        8.54715779e-02,  5.85637651e-02, -4.73560058e-02, -5.20822499e-03,\n",
              "       -9.27715842e-03,  4.12191451e-02,  2.21475679e-02,  8.02465230e-02,\n",
              "       -7.95414820e-02, -1.41363805e-02, -7.50593990e-02,  1.46668861e-02,\n",
              "        7.97520503e-02,  4.23329771e-02, -1.01549374e-02,  9.68345255e-03,\n",
              "       -5.62676899e-02, -2.76991515e-03, -4.50135395e-02, -3.63397114e-02,\n",
              "       -2.88632512e-03,  3.14908624e-02,  6.61040144e-03, -1.19037023e-02,\n",
              "        1.83691792e-02, -5.10664135e-02,  1.97625272e-02, -1.35700315e-01,\n",
              "       -8.25428739e-02, -5.24217859e-02, -3.59555557e-02, -3.13281529e-02,\n",
              "       -8.72447118e-02, -7.45845884e-02, -5.31625876e-04, -3.61732766e-02,\n",
              "        2.95988601e-02, -4.87455539e-02, -8.31213221e-02,  5.93954772e-02,\n",
              "       -3.35073769e-02,  2.81962380e-02, -5.13702855e-02,  6.04946390e-02,\n",
              "       -8.24005380e-02, -6.62563965e-02,  3.00803427e-02, -4.77372520e-02,\n",
              "        8.86089876e-02, -1.14682876e-02,  2.85840165e-02, -1.79408733e-02,\n",
              "        2.91705839e-02, -2.59475838e-02, -3.44714262e-02,  1.72092523e-02,\n",
              "        2.10048668e-02, -8.81040171e-02,  4.90192929e-03,  3.91785009e-03,\n",
              "        5.66373318e-02,  4.85491864e-02, -7.00368453e-03,  2.91876998e-02,\n",
              "        4.37514260e-02, -4.69061136e-02, -3.28719020e-02, -2.56725010e-02,\n",
              "        5.08666523e-02,  2.94409208e-02, -9.50891804e-03,  3.70850414e-03,\n",
              "       -2.54460014e-02,  6.14704564e-04,  9.70900897e-03, -8.83906707e-02,\n",
              "       -8.99428055e-02,  2.05951277e-02,  8.50876514e-03, -9.66524035e-02,\n",
              "        1.48862572e-02,  1.45156048e-02,  3.08693983e-02,  5.59280477e-02,\n",
              "        4.22499105e-02, -2.95278840e-02, -1.42858341e-01,  2.16566380e-02,\n",
              "        4.70048003e-02, -3.33615555e-03,  1.26746586e-02,  1.58542916e-02,\n",
              "       -6.06146306e-02,  5.68511104e-03, -3.41108106e-02, -2.23597344e-02,\n",
              "       -5.75657263e-02,  6.71762303e-02, -2.92481836e-02,  8.91443044e-02,\n",
              "       -1.72110293e-02,  2.31837146e-02, -9.36505198e-03, -3.47036049e-02,\n",
              "        5.11917286e-02, -2.45199818e-02,  3.19132581e-02,  1.30963679e-02,\n",
              "        3.70483659e-02,  4.93873097e-02,  4.58216593e-02,  3.11194919e-02,\n",
              "        5.87021038e-02,  2.86020339e-02,  6.03839429e-03,  3.68666798e-02,\n",
              "       -1.03881704e-02,  1.70054531e-03,  1.17167337e-02,  1.98467784e-02,\n",
              "        1.48200378e-01,  3.59525084e-02,  4.23457846e-02,  3.62095647e-02,\n",
              "       -7.11338688e-03,  3.17213312e-02,  3.22097614e-02,  2.77051255e-02,\n",
              "       -3.17094289e-02,  9.15603265e-02,  3.56624648e-02,  7.60837877e-03,\n",
              "       -3.69629189e-02,  9.58454162e-02, -5.32883592e-02,  4.34087701e-02,\n",
              "        4.29520831e-02, -5.41078933e-02, -5.00095561e-02,  3.44248079e-02,\n",
              "       -1.36768157e-02, -1.14533224e-03,  1.69692039e-02,  5.39893582e-02,\n",
              "        2.69198399e-02, -1.93695035e-02, -2.71186908e-03,  1.06195994e-02,\n",
              "       -1.95283275e-02,  1.61357839e-02,  2.42574606e-02, -3.78023610e-02,\n",
              "        1.51027804e-02, -4.71470058e-02, -5.00968285e-02,  6.34373259e-03,\n",
              "       -2.04296447e-02,  3.89486477e-02,  7.17150047e-02, -6.10053428e-02,\n",
              "        2.65750512e-02, -7.69235846e-03,  2.91217715e-02,  2.20773648e-02,\n",
              "       -3.05016451e-02,  9.57315862e-02,  1.06307575e-02,  3.82872336e-02,\n",
              "        1.21221440e-02,  8.73533785e-02, -5.14507368e-02, -5.76517079e-03,\n",
              "        1.51621243e-02, -4.92335930e-02, -2.24688556e-03, -4.28351387e-02,\n",
              "       -3.75622995e-02,  2.14859080e-02,  1.79149862e-02, -3.97252329e-02,\n",
              "        8.63847602e-03, -3.61412764e-02,  2.14099907e-03, -1.65015366e-02,\n",
              "       -7.00033084e-03, -3.65552567e-02,  1.67008638e-02, -1.40723968e-02,\n",
              "        6.63336192e-04, -3.67025658e-02,  3.77225168e-02, -1.21849934e-02,\n",
              "        2.83187851e-02,  8.35291576e-03,  6.13777153e-02,  4.03296836e-02,\n",
              "       -4.52169925e-02, -9.03317705e-03,  3.94935347e-03,  1.14877924e-01,\n",
              "       -2.87455842e-02, -2.69201603e-02, -8.28011706e-02, -1.00298077e-01,\n",
              "        1.41426222e-02, -3.26199853e-03, -3.35870720e-02, -2.41020340e-02,\n",
              "        1.65404137e-02,  5.28325513e-02,  2.12855563e-02,  3.72219346e-02,\n",
              "        6.70698732e-02,  4.13109921e-03, -1.05351647e-02, -1.42203895e-02,\n",
              "       -4.33747955e-02, -3.88956890e-02,  3.01676467e-02, -1.24645419e-02,\n",
              "        2.78728898e-03, -6.93244208e-03,  3.77367474e-02,  2.24253759e-02,\n",
              "        2.42200438e-02, -2.13177819e-02, -1.45046674e-02, -5.14064822e-03,\n",
              "        2.55382899e-03, -4.37453426e-02, -4.83091213e-02,  8.98236111e-02,\n",
              "        3.99637595e-02, -2.16076430e-02, -2.78507266e-03,  7.66610056e-02,\n",
              "        9.76247620e-03,  2.37820428e-02,  1.03054449e-01, -2.85051279e-02,\n",
              "        4.57690004e-03, -1.06987581e-01,  1.65460887e-03,  1.08399307e-02,\n",
              "       -3.31568271e-02,  1.15578780e-02, -4.62076738e-02,  3.42738554e-02,\n",
              "       -3.09151318e-02,  2.69689914e-02,  5.60879800e-03,  2.15870291e-02,\n",
              "       -5.13517968e-02,  3.65614099e-03, -1.85999516e-02,  5.32488339e-02,\n",
              "        1.00007923e-02, -9.26879421e-02,  1.24752680e-02, -9.89166796e-02,\n",
              "        1.49804279e-02, -3.67246894e-03, -2.68669352e-02, -4.34258021e-02,\n",
              "        9.21010133e-03, -2.08337456e-02, -3.76179232e-03,  7.74091333e-02,\n",
              "       -3.93624529e-02,  7.34356716e-02, -2.57823570e-03, -2.88213454e-02,\n",
              "        6.49443921e-03,  2.83528194e-02,  3.98588032e-02,  8.81356895e-02,\n",
              "       -2.97437273e-02, -2.48173177e-02, -3.52805108e-02,  4.81878743e-02,\n",
              "       -2.10914239e-02, -2.45536765e-04,  3.96146402e-02, -4.09000441e-02,\n",
              "       -3.00859325e-02,  1.26508474e-02, -2.39239330e-03,  2.71387380e-02,\n",
              "        2.14878172e-02, -7.97066689e-02,  4.82078362e-03,  2.72272062e-02,\n",
              "       -4.27303687e-02,  1.63216852e-02, -2.89588850e-02,  9.07153562e-02,\n",
              "       -3.92286181e-02,  6.28829598e-02, -1.63904354e-02,  1.74034052e-02,\n",
              "       -5.24871461e-02,  2.79299989e-02,  4.41449471e-02,  3.81703302e-02,\n",
              "        6.02327138e-02, -6.01882450e-02, -2.07202160e-03, -2.38520978e-03,\n",
              "       -9.22099396e-04, -3.50860320e-02, -1.79485567e-02, -3.99851501e-02,\n",
              "        3.80258188e-02,  5.81928436e-03, -1.75062940e-02, -1.43912220e-02,\n",
              "       -1.88390054e-02,  1.13170154e-01, -6.40609637e-02, -7.23131821e-02,\n",
              "       -2.05054078e-02, -6.02426752e-02,  1.20316660e-02, -7.48610031e-03,\n",
              "       -1.72596369e-02, -2.73319776e-03, -9.65450704e-03, -7.41420239e-02,\n",
              "       -1.68084763e-02,  2.74238866e-02,  7.50973970e-02, -3.15075815e-02,\n",
              "        6.06773570e-02, -1.77636102e-03, -2.06731055e-02,  5.71253486e-02,\n",
              "        2.01734789e-02, -4.96521592e-02, -4.13238257e-02, -1.98553074e-02,\n",
              "        7.33709801e-03, -3.04019824e-02, -1.86798777e-02,  2.37525664e-02,\n",
              "       -6.32604286e-02,  2.93251649e-02, -1.79723219e-03,  3.39430980e-02,\n",
              "        5.32454103e-02, -7.52142817e-02, -6.06065691e-02, -2.46305298e-02,\n",
              "       -5.46315275e-02, -1.14637792e-01,  2.92891301e-02,  6.10700585e-02,\n",
              "        1.22949118e-02, -3.20320129e-02,  1.44228889e-02, -9.99345444e-03,\n",
              "       -5.09206802e-02,  4.04192619e-02, -4.40445244e-02,  6.55966103e-02,\n",
              "        3.19262929e-02, -3.24597582e-02, -1.71565190e-02,  2.46003158e-02,\n",
              "       -1.54929206e-04,  2.33350229e-02, -1.62446091e-03,  6.09595440e-02,\n",
              "       -2.68336702e-02, -1.93970222e-02, -3.52038518e-02, -2.32867710e-02,\n",
              "       -5.97450323e-02,  7.15385079e-02,  8.50118101e-02,  1.17288440e-01,\n",
              "       -1.72792338e-02,  5.80070727e-02,  6.03232868e-02,  3.53287980e-02,\n",
              "       -3.21235247e-02, -2.19052732e-02, -6.67875931e-02, -2.42928434e-02,\n",
              "        8.29760879e-02,  6.00026697e-02,  3.45895737e-02,  4.89646792e-02,\n",
              "       -2.53018923e-02, -4.90279421e-02, -4.04543690e-02, -3.82700823e-02,\n",
              "       -2.68285517e-02,  3.49381659e-03,  3.01038437e-02, -1.46813039e-03,\n",
              "       -6.02994114e-02, -5.70144691e-02,  2.13950817e-02,  2.92146280e-02,\n",
              "        1.90934688e-02, -7.78953508e-02, -2.21378524e-02,  5.67838699e-02,\n",
              "        2.35221852e-02, -1.11557662e-01,  1.21968761e-02, -1.14665940e-01,\n",
              "        5.06443419e-02,  2.89933756e-03,  2.38087531e-02, -5.64510599e-02,\n",
              "        8.37108865e-02,  1.07489107e-02,  5.00915237e-02, -4.55174930e-02,\n",
              "        2.31523290e-02,  1.59411263e-02, -1.00823574e-01,  4.34959419e-02,\n",
              "       -7.62930736e-02,  1.27093736e-02,  3.87201384e-02, -4.75631282e-02,\n",
              "       -4.31633145e-02,  3.62972580e-02,  7.42781535e-03, -4.45608199e-02],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ],
      "source": [
        "q3 = create_image_embedding('./images/q3.jpg')\n",
        "q3\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pr7oM5Otf2My",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a98936e-3bea-4e22-a060-6cf31b0265e7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data: [\"[{'id': 1, 'distance': 0.525050163269043, 'entity': {'person_name': 'Qasim', 'id': 1}}]\"] \n"
          ]
        }
      ],
      "source": [
        "res = client.search(\n",
        "    collection_name=\"images\",\n",
        "    data=[q3],\n",
        "    limit=1,\n",
        "    output_fields=[\"id\", \"person_name\"],\n",
        ")\n",
        "print(res)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kaxs40aDamtV"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "2ce2cdbfdd4d44939090b222e561440b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e3a87c1b2fe24f41a169c76c46dd7e8d",
              "IPY_MODEL_ae9bf4536dc8413083a3e30058195f57",
              "IPY_MODEL_0bfa5dc73eca43dea3cd9bc2bd65da99"
            ],
            "layout": "IPY_MODEL_051bef3984264e45a46c6b7d77bc9bf6"
          }
        },
        "e3a87c1b2fe24f41a169c76c46dd7e8d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9cf4ba41050c4429bf9971792b44436a",
            "placeholder": "​",
            "style": "IPY_MODEL_dd2c74038ad5442495ddbab7696cee52",
            "value": "100%"
          }
        },
        "ae9bf4536dc8413083a3e30058195f57": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_926afd6328d546c69d7807a1a38c4fa4",
            "max": 111898327,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_281c1287cca54141bb01681de8b391d1",
            "value": 111898327
          }
        },
        "0bfa5dc73eca43dea3cd9bc2bd65da99": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_09de6b2d0d8849708685ce674426c1c4",
            "placeholder": "​",
            "style": "IPY_MODEL_9847c2aefcaa43ceb2db27639043574e",
            "value": " 107M/107M [00:00&lt;00:00, 259MB/s]"
          }
        },
        "051bef3984264e45a46c6b7d77bc9bf6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9cf4ba41050c4429bf9971792b44436a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dd2c74038ad5442495ddbab7696cee52": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "926afd6328d546c69d7807a1a38c4fa4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "281c1287cca54141bb01681de8b391d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "09de6b2d0d8849708685ce674426c1c4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9847c2aefcaa43ceb2db27639043574e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}